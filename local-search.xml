<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>优劣解距离法-TOPSIS</title>
    <link href="/2025/04/01/2025-04-01-%E4%BC%98%E5%8A%A3%E8%A7%A3%E8%B7%9D%E7%A6%BB%E6%B3%95-TOPSIS/"/>
    <url>/2025/04/01/2025-04-01-%E4%BC%98%E5%8A%A3%E8%A7%A3%E8%B7%9D%E7%A6%BB%E6%B3%95-TOPSIS/</url>
    
    <content type="html"><![CDATA[<h1 id="优劣解距离法-topsis">优劣解距离法-TOPSIS</h1><h2 id="一建模">一、建模</h2><p>TOPSIS进行建模，大致分为以下四个步骤：</p><ol type="1"><li>将原始矩阵正向化</li><li>将正向化矩阵标准化</li><li>计算得分并归一化</li></ol><p>个人感觉跟熵权法是有很多的相通之处的，二者应该可以相互混着用。</p><h3 id="第一步将原始矩阵正向化">第一步：将原始矩阵正向化</h3><p>在生活中，常见的指标有四种：</p><table><thead><tr><th>指标名称</th><th>指标特点</th><th>例子</th></tr></thead><tbody><tr><td>极大型（效益型）指标</td><td>越大（多）越好</td><td>成绩、GDP增速、企业利润</td></tr><tr><td>极小型（成本型）指标</td><td>越小（少）越好</td><td>费用、坏品率、污染程度</td></tr><tr><td>中间型指标</td><td>越接近某个值越好</td><td>水质量评估时的PH值</td></tr><tr><td>区间型指标</td><td>落在某个区间最好</td><td>体温、水中植物性营养物量</td></tr></tbody></table><p>那么，在TOPSIS方法中，就是要将所有指标进行统一正向化，即统一转化为极大型指标。那么就需要极小型、中间型以及区间型的指标进行转化为极大型指标。</p><p><strong>极小型转极大型</strong>： <span class="math display">\[x_{new}= \frac{\max - x_i}{\max - \min}\]</span> 如果所有的元素均为正数，那么也可以使用：</p><p><span class="math display">\[x_{new}=\frac{1}{x_i}\]</span></p><p><strong>中间型转极大型：</strong>指标值既不要太大也不要太小，取某特定值最好（如水质量评估PH值）。设<spanclass="math inline">\(\{x_i\}\)</span>是一组中间型指标序列，且最佳的数据为<span class="math inline">\(x_{best}\)</span>，那么正向化的公式如下：<span class="math display">\[M = \max\{|x_i - x_{best}|\}\]</span> <span class="math display">\[\bar{x}_i = 1 - \frac{|x_i - x_{best}|}{M}\]</span> <strong>区间型指标：</strong>指标值落在某个区间内最好，例如人的体温在36°～37°这个区间比较好。设<spanclass="math inline">\(\{x_i\}\)</span>是一组区间型指标序列，且最佳的区间为<spanclass="math inline">\([a,b]\)</span>，那么正向化的公式如下： <spanclass="math display">\[M = \max\{a - \min\{x_i\}, \max\{x_i\} - b\},\ \tilde{x}_i =\begin{cases}1 - \frac{a - x_i}{M}, &amp; x_i &lt; a \\1, &amp; a \leq x_i \leq b \\1 - \frac{x_i - b}{M}, &amp; x_i &gt; b\end{cases}\]</span> 实际上这里跟熵权法里面讲过的那个正向化基本上一模一样，具体见<ahref="熵权法(EWM).md">熵权法</a></p><h3 id="第二步正向化矩阵标准化">第二步：正向化矩阵标准化</h3><p>标准化的目的就是消除不同量纲的影响。</p><p>假设有n个要评价的对象，m个评价指标（已经正向化了）构成的正向化矩阵如下：</p><p><span class="math display">\[X =\begin{bmatrix}x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1m} \\x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2m} \\\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nm}\end{bmatrix}\]</span> 那么对其标准化后的矩阵记为Z，Z的每一个元素：</p><p><span class="math display">\[z_{ij} = \frac{x_{ij}}{\sqrt{\sum_{i=1}^{n}x_{ij}^2}}\]</span> 标准化矩阵Z：</p><p><span class="math display">\[Z =\begin{bmatrix}z_{11} &amp; z_{12} &amp; \cdots &amp; z_{1m} \\z_{21} &amp; z_{22} &amp; \cdots &amp; z_{2m} \\\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\z_{n1} &amp; z_{n2} &amp; \cdots &amp; z_{nm}\end{bmatrix}\]</span>注意：标准化的方法不唯一，但目的都是为了去量纲。比如熵权法那一章就还介绍过存在负数时直接上</p><p><span class="math display">\[z_{ij} = \frac{x_{ij} - \min\{x_{1j}, x_{2j}, \ldots,x_{nj}\}}{\max\{x_{1j}, x_{2j}, \ldots, x_{nj}\} - \min\{x_{1j}, x_{2j},\ldots, x_{nj}\}}\]</span></p><h3 id="第三步计算得分并归一化">第三步：计算得分并归一化</h3><p>最大值：</p><p><span class="math display">\[Z^+ = (\max\{z_{11},z_{21},\cdots,z_{n1}\},\max\{z_{12},z_{22},\cdots,z_{n2}\}, \cdots,\max\{z_{1m},z_{2m},\cdots,z_{nm}\})\]</span> 最小值： <span class="math display">\[Z^- = (\min\{z_{11},z_{21},\cdots,z_{n1}\},\min\{z_{12},z_{22},\cdots,z_{n2}\}, \cdots,\min\{z_{1m},z_{2m},\cdots,z_{nm}\})\]</span> 定义第 <span class="math inline">\(i(i =1,2,…,n)\)</span>个评价对象与最大值的距离： <spanclass="math display">\[D_i^+ = \sqrt{\sum_{j=1}^{m}(Z_j^+ - z_{ij})^2}\]</span> 定义第 <span class="math inline">\(i(i = 1,2,…,n)\)</span>个评价对象与最小值的距离：</p><p><span class="math display">\[D_i^- = \sqrt{\sum_{j=1}^{m}(Z_j^- - z_{ij})^2}\]</span> 那么，我们可以计算得出第 <span class="math inline">\(i(i =1,2,…,n)\)</span> 个评价对象未归一化的得分：</p><p><span class="math display">\[S_i = \frac{D_i^-}{D_i^+ + D_i^-}\]</span> 很明显 <span class="math inline">\(0 \leq S_i \leq1\)</span>，且 <span class="math inline">\(S_i\)</span> 越大 <spanclass="math inline">\(D_i^+\)</span> 越小，即越接近最大值。</p><h2 id="二扩展">二、扩展</h2><h4 id="权重结合">权重结合</h4><p>上述过程默认了各项指标的权重相同，但在实际的评价中指标都是有各自的权重，因此应该用权重对公式进行修正，修正后的公式如下，ω代表权重。<span class="math display">\[D_i^+ = \sqrt{\sum_{j=1}^{m}\omega_j(Z_j^+ - z_{ij})^2},\ D_i^- =\sqrt{\sum_{j=1}^{m}\omega_j(Z_j^- - z_{ij})^2}\]</span> 这里就可以直接上熵权法，当然，专家瞎打分也不是不行。</p><h4 id="本质推导">本质推导</h4><p>公式：</p><p><span class="math display">\[S_i = \frac{D_i^-}{D_i^+ + D_i^-}\]</span> 实际上是：</p><p><span class="math display">\[\frac{x - \min}{\max - \min} \rightarrow \frac{x - \min}{(\max - x) + (x- \min)} \rightarrow \frac{x与最小值的距离}{x与最大值的距离 +x与最小值的距离}\]</span> <span class="math inline">\(D_i^+\)</span>与<spanclass="math inline">\(D_i^-\)</span>实际上是<strong>欧氏距离</strong>，这个的本质思想和熵权法的实际上是有很多的相同之处的。</p><h2 id="参考">参考</h2><p><ahref="https://blog.csdn.net/weixin_43819566/article/details/112342602">清风数学建模学习笔记——TOPSIS法（优劣解距离法）-CSDN博客</a></p><p><ahref="https://zhuanlan.zhihu.com/p/564302492">数学建模——常考评价类模型介绍- 知乎</a></p><p><ahref="https://zhuanlan.zhihu.com/p/266689519">TOPSIS(逼近理想解)算法原理详解与代码实现- 知乎</a></p>]]></content>
    
    
    <categories>
      
      <category>数学</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模，算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模糊综合评价法-FCE</title>
    <link href="/2025/04/01/2025-04-01-%E6%A8%A1%E7%B3%8A%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%B3%95-FCE/"/>
    <url>/2025/04/01/2025-04-01-%E6%A8%A1%E7%B3%8A%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%B3%95-FCE/</url>
    
    <content type="html"><![CDATA[<h1 id="模糊综合评价法">模糊综合评价法</h1><p>量分为 <strong>确定性</strong> 和 <strong>不确定性</strong>：</p><ul><li><strong>确定性</strong>：经典数学（几何、代数）</li><li><strong>不确定性</strong>：<ol type="1"><li>随机性（概率论、随机过程）如掷筛子，观看那一面向上，这种现象的规律性靠概率统计去刻画。</li><li>灰性（灰色系统）</li><li>模糊性（模糊数学）如“今天天气很热”、“小伙子很帅”等，靠模糊数学去刻画。</li></ol></li></ul><p>而模糊综合评价法是一种基于 <strong>模糊数学</strong> 的综合<strong>评价方法</strong>。该综合评价法根据模糊数学的<strong>隶属度理论</strong>把定性评价转化为定量评价，即用模糊数学对受到多种因素制约的事物或对象做出一个总体的评价。它具有结果清晰，系统性强的特点，能较好地解决模糊的、难以量化的问题，适合各种<strong>非确定性问题的解决</strong>。</p><h2id="经典集合和模糊集合的基本概念">1、经典集合和模糊集合的基本概念</h2><h3 id="经典集合classical-set和特征函数">1.1 经典集合（classicalset）和特征函数</h3><ul><li><strong>经典集合</strong>：具有相同属性的事物的集体，例如：颜色、性别、手机品牌等、自然数集。</li><li>集合的基本属性：互斥、确定，就是从高中以来我们一直所认为的集合。</li></ul><h3 id="模糊集合fuzzy-set和隶属函数">1.2 模糊集合（fuzzyset）和隶属函数</h3><ul><li><p><strong>模糊集合</strong>：用来描述模糊性概念的集合。（帅、高、白、年轻…）</p></li><li><p>与经典集合相比，模糊集合承认亦此亦彼，即不具有确定性和互斥性，而我们很多情况下都是这样的集合，比如25年第一次校赛B题。</p></li><li><p>数学中对于模糊集合的刻画：<strong>隶属函数</strong></p><p><span class="math display">\[\mathbf{u_A: U \rightarrow [0,1]}\]</span> 其中注意与 <span class="math inline">\(\{0, 1\}\)</span>的区别，<span class="math inline">\(\{0, 1\}\)</span>只有两种可能，<span class="math inline">\([0, 1]\)</span>有无数种可能。</p></li></ul><h2 id="隶属函数的确定方法">2、隶属函数的确定方法</h2><h3 id="模糊统计法">2.1 模糊统计法</h3><p>自己捏数或者放问卷。</p><h3 id="借助已有的客观尺度">2.2 借助已有的客观尺度</h3><p>比如用恩格尔系数描述家庭贫富状况。</p><h3 id="指派法">2.3 指派法</h3><p><strong>根据问题的性质直接套用某些分布作为隶属函数，主观性较强。</strong></p><figure><imgsrc="https://i-blog.csdnimg.cn/blog_migrate/533fb99c13fa8f6ca63aeb208c4bf273.png#pic_center"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>其中，梯形分布用得较多。</p><h2 id="应用模糊综合评价评判">3、 应用：模糊综合评价(评判)</h2><h3 id="评价问题概述">3.1 评价问题概述</h3><p>模糊评价问题是要解决的问题是：</p><blockquote><p>① 把论域中的对象对应评语集中的一个指定的评语。 ②将方案作为评语集并选择一个最优的方案。</p></blockquote><p>在模糊综合评价中，引入三个集合：（下面的符号和概念中的符号表示的<strong>含义不同</strong>）</p><ul><li><strong>因素集（评价指标集）</strong> <span class="math inline">\(U= \{u_1,u_2,...,u_n\}\)</span></li><li><strong>评语集（评价的结果集）</strong> <spanclass="math inline">\(V = \{v_1,v_2,..,v_m\}\)</span></li><li><strong>权重集（指标的权重）</strong> <span class="math inline">\(A= \{a_1,a_2,...,a_n\}\)</span></li></ul><h3 id="一级模糊综合评价">3.2 一级模糊综合评价</h3><ol type="1"><li><p><strong>确定因素集</strong></p><p>一级模糊评价中，(n) 往往较小（一般 ≤ 5）且指标间相关性不强。</p></li><li><p><strong>确定评语集</strong></p></li><li><p><strong>第三步：确定各因素的权重</strong></p><p>确定权重的方法有很多，如：Delphi法（专家调查法，即瞎几把捏数法）、加权平均法、众人评估法。但是建议：当没有数据的时候可采取层次分析法，有数据的时候可采取熵权法。</p></li><li><p><strong>第四步：确定模糊综合评判矩阵，对每个元素 ui做出评价</strong></p></li><li><p><strong>第五步：模糊综合评判</strong></p></li></ol><h3 id="多级模糊综合评价">3.3 多级模糊综合评价</h3><p>一级模糊综合评价是多级模糊综合评价的基础。它是将一级模糊评价因素集指标的相关性指标进行统一综合，因为上文讲过一级模糊评价的指标之间是相关性不强的，那么这样相关性指标在只考虑这一种因素的情况下是不相关的，即相对不相关。然后对每个相关性指标进行综合，求得只看这一组指标对于评语集的隶属度，此方法进行类推，最后再综合。</p><h2 id="模型总结">4、模型总结</h2><ol type="1"><li>隶属函数有三种确定方法，要根据实际情况来选择使用。</li><li>极大型（极小型）指标，和模糊集合的三类（偏小型、中间型、偏大型）是两种概念，注意区分。</li><li>模糊综合评价的因素指标是相关性不强的，如果有相关项较强的需要进行多级模糊综合评价，级数一般不超过3层。</li></ol>]]></content>
    
    
    <categories>
      
      <category>数学</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模，算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>主成分分析-PCA</title>
    <link href="/2025/04/01/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-PCA/"/>
    <url>/2025/04/01/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-PCA/</url>
    
    <content type="html"><![CDATA[<h1 id="主成分分析-pca">主成分分析-PCA</h1><p>主成分分析（PCA）是一种降维算法，通过将原始变量进行线性组合，生成互不相关的主成分，从而保留数据的主要信息，以此来去噪，提升数据处理速度。PCA常用于数据简化、聚类分析及解决回归中多重共线性问题，但在解释主成分时往往较为模糊，故不常用于评价模型。</p><hr /><h2 id="一主成分分析简介">一、主成分分析简介</h2><ul><li><strong>目标：</strong>用较少的新变量替代原来较多的变量，尽可能保留原有信息。<br /></li><li><strong>应用：</strong> 数据降维、去除噪声、提升数据处理速度。<br /></li><li><strong>适用场景</strong>：指标高度相关易于解释、可解释需求低。</li><li><strong>局限性</strong>：非线性关系处理的不好，贡献度若是不足可能会丢失细节。</li></ul><hr /><h2 id="二主成分分析的思想">二、主成分分析的思想</h2><p>假设有 <span class="math inline">\(n\)</span> 个样本和 <spanclass="math inline">\(p\)</span> 个指标，构成一个 $ n p$的样本矩阵：</p><p><span class="math display">\[X = \begin{bmatrix}x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \\x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} \\\end{bmatrix}= (x_1, x_2, \cdots, x_p)\]</span> 目标是寻找新的变量 $ z_1, z_2, , z_m $（其中 $ m p$），使其满足：</p><p><span class="math display">\[\begin{cases}z_1 = l_{11}x_1 + l_{12}x_2 + \cdots + l_{1p}x_p \\z_2 = l_{21}x_1 + l_{22}x_2 + \cdots + l_{2p}x_p \\\vdots \\z_m = l_{m1}x_1 + l_{m2}x_2 + \cdots + l_{mp}x_p \\\end{cases}\]</span> <strong>系数 $ l_{ij} $ 的确定原则：</strong></p><ol type="1"><li>不同主成分之间彼此不相关。</li><li>第一主成分是所有线性组合中方差最大的。</li><li>第二主成分在与第一主成分不相关的条件下方差最大。</li><li>依此类推，直到选出 $ m $ 个主成分。</li></ol><hr /><h2 id="三主成分分析的计算步骤">三、主成分分析的计算步骤</h2><h3 id="数据标准化">1. 数据标准化</h3><ul><li><p><strong>计算均值和标准差：</strong></p><p><span class="math display">\[\bar{x}_j = \frac{1}{n} \sum_{i=1}^{n} x_{ij},\quad S_j =\sqrt{\frac{\sum_{i=1}^{n}(x_{ij}-\bar{x}_j)^2}{n-1}}\]</span></p></li><li><p><strong>标准化数据：</strong> <span class="math display">\[X_{ij} = \frac{x_{ij}-\bar{x}_j}{S_j}\]</span></p></li><li><p><strong>标准化后的矩阵：</strong></p><p><span class="math display">\[X = \begin{bmatrix}X_{11} &amp; X_{12} &amp; \cdots &amp; X_{1p} \\X_{21} &amp; X_{22} &amp; \cdots &amp; X_{2p} \\\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\X_{n1} &amp; X_{n2} &amp; \cdots &amp; X_{np} \\\end{bmatrix}\]</span></p></li></ul><h3 id="计算协方差矩阵">2. 计算协方差矩阵</h3><ul><li><strong>定义：</strong> <span class="math display">\[R = \begin{bmatrix}r_{11} &amp; r_{12} &amp; \cdots &amp; r_{1p} \\r_{21} &amp; r_{22} &amp; \cdots &amp; r_{2p} \\\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\r_{p1} &amp; r_{p2} &amp; \cdots &amp; r_{pp} \\\end{bmatrix},\quad r_{ij} = \frac{1}{n-1}\sum_{k=1}^{n} X_{ki} X_{kj}\]</span></li></ul><h3 id="求解特征值和特征向量">3. 求解特征值和特征向量</h3><ul><li><p><strong>特征值：</strong> <span class="math display">\[\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_p \geq 0\]</span> （且 $ R $ 为半正定矩阵，满足 $(R) = _{k=1}^{p}_k = p $）</p></li><li><p><strong>对应的特征向量：</strong></p><p><span class="math display">\[a_1 = \begin{bmatrix} a_{11} \\ a_{21} \\ \vdots \\ a_{p1}\end{bmatrix},\quada_2 = \begin{bmatrix} a_{12} \\ a_{22} \\ \vdots \\ a_{p2}\end{bmatrix},\quad \dots,\quada_p = \begin{bmatrix} a_{1p} \\ a_{2p} \\ \vdots \\ a_{pp} \end{bmatrix}\]</span></p></li></ul><h3 id="计算贡献率和累计贡献率">4. 计算贡献率和累计贡献率</h3><ul><li><p><strong>贡献率：</strong></p><p><span class="math display">\[\text{贡献率} = \frac{\lambda_i}{\sum_{k=1}^{p}\lambda_k}\]</span></p></li><li><p><strong>累计贡献率：</strong></p><p><span class="math display">\[\text{累计贡献率} =\frac{\sum_{k=1}^{i}\lambda_k}{\sum_{k=1}^{p}\lambda_k}\quad(i=1,2,\dots,p)\]</span></p></li></ul><h3 id="写出主成分">5. 写出主成分</h3><p>一般选择累计贡献率超过 80% 的前 ( m ) 个主成分：</p><p><span class="math display">\[F_i = a_{1i}X_1 + a_{2i}X_2 + \cdots + a_{pi}X_p,\quad (i=1,2,\dots,m)\]</span></p><h3 id="主成分的解释">6. 主成分的解释</h3><p>根据各指标在主成分中的载荷大小判断该主成分代表的含义，载荷越大的指标对该主成分的影响越大。</p><hr /><h2 id="四扩展">四、扩展</h2><ol type="1"><li><strong>聚类分析：</strong>可通过降维简化自变量，便于图形展示。</li><li><strong>回归分析：</strong> 可用于缓解多重共线性问题。</li><li><strong>因子分析：</strong> PCA实际上是因子分析的一种特例，但因子分析在解释方面更具优势，建议多用因子分析。</li></ol><hr /><h2 id="参考资料">参考资料</h2><p><ahref="https://blog.csdn.net/weixin_43819566/article/details/113800120">清风数学建模学习笔记——主成分分析(PCA)原理详解及案例分析_x10为生均教育经费对以上指标数据做主成分分析，并提取主成分-CSDN博客</a></p><p><ahref="https://developer.baidu.com/article/details/3015610">数学建模中的主成分分析(PCA)详解与应用-百度开发者中心</a></p><p><ahref="https://zhuanlan.zhihu.com/p/677797684">【数模百科】一文讲清楚主成分分析PCA（附python代码）- 知乎</a></p>]]></content>
    
    
    <categories>
      
      <category>数学</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模，算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>皮尔逊相关系数-PEARSON</title>
    <link href="/2025/03/31/%E7%9A%AE%E5%B0%94%E9%80%8A%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/"/>
    <url>/2025/03/31/%E7%9A%AE%E5%B0%94%E9%80%8A%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="皮尔逊相关系数">皮尔逊相关系数</h1><p>方差描述的是单个变量的离散程度，协方差给方差的一个 <spanclass="math inline">\((X - E[X])^2\)</span> 变成 <spanclass="math inline">\((X - E[X])(Y - E[Y])\)</span>，就能衡量的是两个变量偏离各自均值后乘积的平均值，反映了两变量共同变化的趋势。但由于协方差受变量的单位影响，难以直接比较，所以我们就要将其无量纲化，除上各自的标准差就好。</p><h2 id="一定义">一、定义</h2><p>皮尔逊相关系数（通常称为<strong>线性相关系数</strong>）用于刻画变量 X与 Y 之间的线性关系。其定义为： <span class="math display">\[\rho_{X, Y} = \frac{\operatorname{cov}(X, Y)}{\sigma_X \sigma_Y} =\frac{E\left[(X - E[X])(Y - E[Y])\right]}{\sigma_X \sigma_Y} =\frac{E(XY) - E(X)E(Y)}{\sqrt{E\left(X^2\right) - [E(X)]^2}\sqrt{E\left(Y^2\right) - [E(Y)]^2}}\]</span></p><blockquote><p><strong>注：</strong> 当 X 与 Y存在其他非线性关系时，皮尔逊相关系数无法正确反映两者之间的关系。</p></blockquote><hr /><h2 id="二相关系数的性质">二、相关系数的性质</h2><ol type="1"><li><p><strong>独立性与不相关性：</strong></p><p>如果 X 和 Y 独立，则 <span class="math inline">\(\rho_{X,Y} =0\)</span>；但反过来，<span class="math inline">\(\rho_{X,Y} =0\)</span> 不一定说明 X 与 Y 独立，除非二者服从二维正态分布。</p></li><li><p><strong>取值范围：</strong></p></li></ol><p><span class="math display">\[-1 \leq \rho_{X,Y} \leq 1\]</span></p><hr /><h2 id="三两组指标相关系数的计算">三、两组指标相关系数的计算</h2><h3 id="样本均值期望">1. 样本均值（期望）：</h3><p><span class="math display">\[\bar{X} = \frac{1}{n}\sum_{i=1}^{n} X_i,\quad \bar{Y} =\frac{1}{n}\sum_{i=1}^{n} Y_i\]</span></p><h3 id="样本方差无偏估计">2. 样本方差（无偏估计）：</h3><p><span class="math display">\[\sigma_X^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2,\quad\sigma_Y^2 = \frac{1}{n-1}\sum_{i=1}^{n}(Y_i - \bar{Y})^2\]</span></p><h3 id="样本协方差">3. 样本协方差：</h3><p><span class="math display">\[\operatorname{cov}(X,Y) = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})(Y_i- \bar{Y})\]</span></p><h3 id="相关系数">4. 相关系数：</h3><p><span class="math display">\[r = \frac{\sum_{i=1}^{n}(X_i - \bar{X})(Y_i -\bar{Y})}{\sqrt{\sum_{i=1}^{n}(X_i - \bar{X})^2}\sqrt{\sum_{i=1}^{n}(Y_i - \bar{Y})^2}}\]</span></p><blockquote><p><strong>说明：</strong>分母中用的是各自的标准差，目的是将协方差无量纲化，从而消除不同变量之间单位和量级的影响，使得计算结果统一在([-1, 1]) 之间。</p></blockquote><hr /><h2 id="四相关强度的判断标准">四、相关强度的判断标准</h2><p>根据计算得出的相关系数 (r)的绝对值，可以判断两个变量之间的相关性强弱：</p><table><thead><tr><th>|r|</th><th>相关强度</th></tr></thead><tbody><tr><td>0.8-1.0</td><td>极强相关</td></tr><tr><td>0.6-0.8</td><td>强相关</td></tr><tr><td>0.4-0.6</td><td>中等程度相关</td></tr><tr><td>0.2-0.4</td><td>弱相关</td></tr><tr><td>0.0-0.2</td><td>极弱相关或无相关</td></tr></tbody></table><hr /><h2 id="其它参考资源">其它参考资源</h2><ul><li><a href="#">带你深入理解期望、方差、协方差的含义</a></li><li><a href="https://www.zhihu.com/question/19734616">知乎：如何理解Pearson 相关系数</a></li><li><ahref="https://blog.csdn.net/MoreAction_/article/details/106195689">相关系数——皮尔逊相关系数的公式及其理解_皮尔逊相关系数公式-CSDN博客</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>数学</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模，算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>熵权法-EWM</title>
    <link href="/2025/03/31/%E7%86%B5%E6%9D%83%E6%B3%95(EWM)/"/>
    <url>/2025/03/31/%E7%86%B5%E6%9D%83%E6%B3%95(EWM)/</url>
    
    <content type="html"><![CDATA[<h1 id="熵权法ewm">熵权法(EWM)</h1><h2 id="背景">背景</h2><p>一种常见于数学建模的更为客观的分配权重的方法，因为层次分析法主观性太强，专家打分实际上就是自己瞎几把打，故引入熵权法。</p><h2 id="思路">思路</h2><p>对于一组数据指标，如果它的方差越大，就说明这个数据的相似度越小，就是它所贡献度就越大。极端来看，就如果对于某项指标来讲，他的所有的值是一样的，那么它的相似度是最大的，基于这个指标来进行判别的权重可以直接设为0。熵是不确定度的一种度量，不确定性越大，熵就越大，信息量就越大，它的对最终决策的影响权重应该就设置得更高一些。</p><p>举个清风数学建模的例子，小张和小王是两个高中生，小张学习好回回期末考满分，小王学习不好考试常常不及格。在一次考试中，小张还是考了满分，而小王也考了满分。那就很不一样了，小王这里包含的信息就非常大，所对应的权重也就高一些。</p><h2 id="定义">定义</h2><ul><li><p><strong>信息量</strong></p><p>定义信息量为：<br /><span class="math display">\[I(x) = -\ln(p(x))\]</span></p></li><li><p><strong>信息熵</strong> 定义信息熵为各信息量的期望值： <spanclass="math display">\[H(X) = -\sum_{i=1}^{n} p(x_i)\ln(p(x_i))\]</span> 当所有事件均等时，熵达到最大值：<br /><span class="math display">\[H(X) = \ln(n)\]</span></p></li></ul><hr /><h2 id="计算步骤">计算步骤</h2><p>熵权法主要包括以下三个步骤：</p><h3 id="数据标准化">1.数据标准化</h3><p>假设有个对象和个指标，原始数据构成矩阵（要先正向化）：</p><p><span class="math display">\[X = \begin{bmatrix}x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1m} \\x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2m} \\\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nm}\end{bmatrix}\]</span></p><h4 id="判断负数进行正向化处理">1.1 判断负数，进行正向化处理</h4><ul><li><strong>要求</strong>：后续计算概率时，每个元素必须为非负值。<br /></li><li><strong>处理</strong>：如果其中存在负数，则需采用特定方法将其标准化到[0,1] 区间。</li></ul><table><thead><tr><th>指标名称</th><th>指标特点</th><th>例子</th></tr></thead><tbody><tr><td>极大型指标（正向指标）</td><td>越大越好</td><td>成绩、利润、GDP增速</td></tr><tr><td>极小型指标（负向指标）</td><td>越小越好</td><td>花费、污染程度、失业率</td></tr><tr><td>中间型指标</td><td>越接近某个值越好</td><td>水质量评估时的PH值</td></tr><tr><td>区间型指标</td><td>落在某个区间最好</td><td>体温、水中某物质含量</td></tr></tbody></table><ul><li>极小型转极大型：</li></ul><p><span class="math display">\[x_i = \max\{x_1, x_2, ..., x_i\} - x_i\]</span></p><p>注：若所有元素均为正数，可以直接取倒数。</p><ul><li>中间行转极大型：</li></ul><p>中间型指标序列，且最佳数值为 <spanclass="math inline">\(x_{best}\)</span>，<spanclass="math inline">\(x_{new}\)</span>为正向化之后的极大型指标，正向化公式：</p><p><span class="math display">\[  M = \max\{|x_i - x_{best}|\}\]</span></p><p><span class="math display">\[x_{new} = 1 - \frac{|x_i - x_{best}|}{M}\]</span></p><ul><li>区间型转极大型:</li></ul><p>区间型指标序列，且最佳数值为 <spanclass="math inline">\(x_{best}\)</span>，<spanclass="math inline">\(x_{new}\)</span>为正向化之后的极大型指标，正向化公式： <span class="math display">\[M = \max\{a - \min\{x_i\}, \max\{x_i\} - b\}\]</span></p><p><span class="math display">\[x_{new} =\begin{cases}1 - \frac{a - x}{M}, &amp; x &lt; a \\1, &amp; a \leq x \leq b \\1 - \frac{x - b}{M}, &amp; x &gt; b\end{cases}\]</span></p><h4 id="标准化方法归一化">1.2 标准化方法（归一化）</h4><ul><li><p><strong>方法一</strong>（适用于无负数情况）： <spanclass="math display">\[z_{ij} = \frac{x_{ij}}{\sqrt{\sum_{i=1}^{n} x_{ij}^2}}\]</span></p></li><li><p><strong>方法二</strong>（存在负数时）： <spanclass="math display">\[z_{ij} = \frac{x_{ij} - \min\{x_{1j}, x_{2j}, \ldots,x_{nj}\}}{\max\{x_{1j}, x_{2j}, \ldots, x_{nj}\} - \min\{x_{1j}, x_{2j},\ldots, x_{nj}\}}\]</span></p></li></ul><hr /><h3 id="计算概率矩阵">2.计算概率矩阵</h3><p>从标准化矩阵出发，计算各样本在每个指标下所占的比重，构成概率矩阵：</p><p><span class="math display">\[p_{ij} = \frac{z_{ij}}{\sum_{i=1}^{n} z_{ij}}\]</span> 这样确保每一列（每个指标）的概率和为1。</p><hr /><h3 id="计算信息熵与熵权">3.计算信息熵与熵权</h3><h4 id="计算信息熵">3.1 计算信息熵</h4><p>计算信息熵：</p><p><span class="math display">\[e_j = -\frac{1}{\ln n} \sum_{i=1}^{n} p_{ij}\ln(p_{ij}) \quad(j=1,2,\ldots,m)\]</span> <em>注意：当 <span class="math inline">\(p_{ij}=0\)</span>时，约定 <span class="math inline">\(\ln(0)=0\)</span> 。</em></p><p>这里除以 <span class="math inline">\(\ln n\)</span> 使得 <spanclass="math inline">\(e_j\)</span> 被归一化到 <spanclass="math inline">\([0,1]\)</span> 区间。</p><h4 id="计算信息效用值">3.2 计算信息效用值</h4><p>定义信息效用值 <span class="math inline">\(d_j\)</span> 为： <spanclass="math display">\[d_j = 1 - e_j\]</span> 信息效用值越大，表示该指标包含的信息越多。</p><h4 id="归一化得到熵权">3.3 归一化得到熵权</h4><p>最终，将各指标的信息效用值归一化，得到熵权 <spanclass="math inline">\(\omega_j\)</span>： <span class="math display">\[\omega_j = \frac{d_j}{\sum_{j=1}^{m} d_j} \quad (j=1,2,\ldots,m)\]</span></p><h4 id="最终得分">4. 最终得分</h4><p><span class="math display">\[score_i =  \sum_{j=1}^{m} w_{j}z_{ij} \quad (i=1,2,\ldots,n)\]</span></p><h2 id="示例代码">示例代码</h2><p>（转自<ahref="https://blog.csdn.net/m0_46246301/article/details/106735607">这篇帖子</a>）</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-comment">% 代码实战一下吧，如下是清风老师的课程里的例子，自己再敲了一下代码并简化了一丢丢？</span><br>clc,clear;<br><br><span class="hljs-comment">% 定义函数</span><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">[lnP]</span> = <span class="hljs-title">My_log</span><span class="hljs-params">(P)</span></span><br>    <span class="hljs-comment">% 当矩阵P中的元素为0时，返回0</span><br>    n = <span class="hljs-built_in">size</span>(P,<span class="hljs-number">1</span>);<br>    m = <span class="hljs-built_in">size</span>(P,<span class="hljs-number">2</span>);<br>    lnP = <span class="hljs-built_in">zeros</span>(n,m);<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:n*m<br>        <span class="hljs-keyword">if</span> P(<span class="hljs-built_in">i</span>) == <span class="hljs-number">0</span><br>            lnP(<span class="hljs-built_in">i</span>) = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">else</span><br>            lnP(<span class="hljs-built_in">i</span>) = <span class="hljs-built_in">log</span>(P(<span class="hljs-built_in">i</span>));<br>        <span class="hljs-keyword">end</span><br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br><br><span class="hljs-comment">% 传入三个参数：</span><br><span class="hljs-comment">% i为第几列,type为指标类型(1：极小型， 2：中间型， 3：区间型),A_col为对应列向量</span><br><span class="hljs-comment">% 返回正向化后的列向量A_col</span><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">[A_col]</span> = <span class="hljs-title">Positivization</span><span class="hljs-params">(i,type,A_col)</span></span><br>    <br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span> == <span class="hljs-number">1</span>        <span class="hljs-comment">% 极小型</span><br>        <span class="hljs-built_in">disp</span>([<span class="hljs-string">&#x27;第&#x27;</span>,num2str(<span class="hljs-built_in">i</span>),<span class="hljs-string">&#x27;列是极小型&#x27;</span>] )<br>        A_col = min_to_max(A_col);<br>    <span class="hljs-keyword">elseif</span> <span class="hljs-built_in">type</span> == <span class="hljs-number">2</span>    <span class="hljs-comment">% 中间型</span><br>        <span class="hljs-built_in">disp</span>([<span class="hljs-string">&#x27;第&#x27;</span>,num2str(<span class="hljs-built_in">i</span>),<span class="hljs-string">&#x27;列是中间型&#x27;</span>] )<br>        value = input(<span class="hljs-string">&#x27;请输入最佳值： &#x27;</span>);<br>        A_col = mid_to_max(A_col, value);<br>    <span class="hljs-keyword">elseif</span> <span class="hljs-built_in">type</span> == <span class="hljs-number">3</span>    <span class="hljs-comment">% 区间型</span><br>        <span class="hljs-built_in">disp</span>([<span class="hljs-string">&#x27;第&#x27;</span>,num2str(<span class="hljs-built_in">i</span>),<span class="hljs-string">&#x27;列是区间型&#x27;</span>] )<br>        l = input(<span class="hljs-string">&#x27;请输入区间的下界： &#x27;</span>);<br>        r = input(<span class="hljs-string">&#x27;请输入区间的上界： &#x27;</span>); <br>        A_col = inter_to_max(A_col, l, r);<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-built_in">disp</span>(<span class="hljs-string">&#x27;没有这种类型的指标,请检查type是否输入错误&#x27;</span>)<br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br><br><span class="hljs-comment">% 1、导入数据</span><br>load data_river.mat<br><span class="hljs-comment">% 2、正向化</span><br>[n,m] = <span class="hljs-built_in">size</span>(A);<br><span class="hljs-built_in">disp</span>([<span class="hljs-string">&#x27;该数据一共有&#x27;</span>,num2str(n),<span class="hljs-string">&#x27;个评价对象,有&#x27;</span>,num2str(m),<span class="hljs-string">&#x27;个评价指标&#x27;</span>])<br>jud = input([<span class="hljs-string">&#x27;这&#x27;</span> num2str(m) <span class="hljs-string">&#x27;个指标是否需要进行正向化处理，需要请输入1 ，不需要输入0：&#x27;</span>]);<br><span class="hljs-keyword">if</span> jud == <span class="hljs-number">1</span><br>    col_list = input(<span class="hljs-string">&#x27;请输入需要正向化的指标所在列组成的列表，如第2、3列，需输入[2,3]: &#x27;</span>);<br>    type_list = input(<span class="hljs-string">&#x27;请输入这些列的指标类型组成的列表（1：极小型， 2：中间型， 3：区间型): &#x27;</span>);<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:<span class="hljs-built_in">size</span>(col_list,<span class="hljs-number">2</span>)  <span class="hljs-comment">% 列</span><br>        A(:,col_list(<span class="hljs-built_in">i</span>)) = Positivization(col_list(<span class="hljs-built_in">i</span>),type_list(<span class="hljs-built_in">i</span>),A(:,col_list(<span class="hljs-built_in">i</span>)));<br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br><span class="hljs-comment">% 3、标准化</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">isempty</span>(<span class="hljs-built_in">find</span>(A &lt; <span class="hljs-number">0</span>))<br>    <span class="hljs-built_in">disp</span>(<span class="hljs-string">&#x27;不存在负数，标准化后的矩阵为:&#x27;</span>)<br>    <span class="hljs-comment">% A_stand = A./ repmat(sum(A.*A).^(1/2),n,1) % 按列求和</span><br>    A_stand = (A - <span class="hljs-built_in">repmat</span>(<span class="hljs-built_in">min</span>(A),n,<span class="hljs-number">1</span>))./(<span class="hljs-built_in">repmat</span>(<span class="hljs-built_in">max</span>(A)-<span class="hljs-built_in">min</span>(A),n,<span class="hljs-number">1</span>)) <br><span class="hljs-keyword">else</span><br>    <span class="hljs-built_in">disp</span>(<span class="hljs-string">&#x27;存在负数，标准化后的矩阵为:&#x27;</span>)<br>    A_stand = (A - <span class="hljs-built_in">repmat</span>(<span class="hljs-built_in">min</span>(A),n,<span class="hljs-number">1</span>))./(<span class="hljs-built_in">repmat</span>(<span class="hljs-built_in">max</span>(A)-<span class="hljs-built_in">min</span>(A),n,<span class="hljs-number">1</span>)) <br><span class="hljs-keyword">end</span><br><span class="hljs-comment">% 4、计算概率矩阵:相当于每个标准化后的指标归一化</span><br><span class="hljs-built_in">disp</span>(<span class="hljs-string">&#x27;概率矩阵为:&#x27;</span>)<br>P = A_stand./<span class="hljs-built_in">repmat</span>(sum(A_stand),n,<span class="hljs-number">1</span>)<br><span class="hljs-comment">% 5、计算每个指标的信息熵</span><br><span class="hljs-built_in">disp</span>(<span class="hljs-string">&#x27;指标的信息熵:&#x27;</span>)<br>E = -sum(P.*My_log(P))/<span class="hljs-built_in">log</span>(n)<br><span class="hljs-comment">% 6、计算权重</span><br><span class="hljs-built_in">disp</span>(<span class="hljs-string">&#x27;指标对应的权重:&#x27;</span>)<br>W = (<span class="hljs-number">1</span>-E)./sum(E)<br><span class="hljs-comment">% 归一化</span><br>W = W./sum(W)<br><span class="hljs-comment">% 7、计算最终得分</span><br><span class="hljs-built_in">disp</span>(<span class="hljs-string">&#x27;最终综合得分为:&#x27;</span>)<br>score = sum(W.*A_stand,<span class="hljs-number">2</span>)<br>score_stand = score ./ sum(score);<br>[score_stand_sort, index] = <span class="hljs-built_in">sort</span>(score_stand, <span class="hljs-string">&#x27;descend&#x27;</span>);<br><span class="hljs-built_in">disp</span>(<span class="hljs-string">&#x27;最终名次为:&#x27;</span>)<br><span class="hljs-built_in">disp</span>(index)<br></code></pre></td></tr></table></figure><hr /><h2 id="扩展">扩展</h2><ol type="1"><li><strong>修正TOPSIS法</strong>：可利用熵权法修正TOPSIS法，使决策更加客观。</li><li><strong>主客观权重综合</strong>：将客观赋权（熵权法）与主观赋权相结合，可获得更合理的权重分配。</li><li><strong>其他客观赋权方法</strong>：例如灰色关联分析法也可作为计算权重的方法。</li><li><strong>标准化方法选择</strong>：不同的标准化方法会得到不同的 (Z)矩阵，需根据实际情况选择合适方法。</li></ol><hr /><h2 id="模型总结">模型总结</h2><ul><li><strong>第一步</strong>：检查输入矩阵中是否存在负数，并进行必要的标准化处理，确保数据非负。</li><li><strong>第二步</strong>：计算每个指标下每个样本的比重，构成概率矩阵。</li><li><strong>第三步</strong>：利用概率矩阵计算各指标的信息熵，然后计算信息效用值，最后归一化得到各指标的权重。</li></ul><hr />]]></content>
    
    
    <categories>
      
      <category>数学</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模，算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>XGBoost公式文档</title>
    <link href="/2025/03/31/XGBoost&#39;s_latex/"/>
    <url>/2025/03/31/XGBoost&#39;s_latex/</url>
    
    <content type="html"><![CDATA[<h1 id="xgboost技术文档">XGBoost技术文档</h1><h2 id="参数设置">参数设置</h2><p>见代码</p><h2 id="涉及到的相关数学公式">涉及到的相关数学公式：</h2><ul><li><strong>模型目标函数</strong>：</li></ul><p><span class="math display">\[\text{Obj}(\theta)^{(t)} = \sum_{i=1}^n L(y_i, \hat{y}_i) + \sum_{k=1}^K\Omega(f_k)\]</span></p><ul><li><strong>正则项</strong></li></ul><p><span class="math display">\[\Omega(f) = \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T w_j^2\]</span></p><ul><li><strong>目标函数近似</strong></li></ul><p><span class="math display">\[\text{Obj}(\theta)^{(t)} \approx \sum_{i=1}^n \left[ g_i f_t(x_i) +\frac{1}{2} h_i f_t^2(x_i) \right] + \Omega(f_t)\]</span></p><ul><li><strong>增益</strong></li></ul><p><span class="math display">\[\text{Gain} = \frac{1}{2} \left[ \frac{(\sum_{i \in I_L} g_i)^2}{\sum_{i\in I_L} h_i + \lambda} + \frac{(\sum_{i \in I_R} g_i)^2}{\sum_{i \inI_R} h_i + \lambda} - \frac{(\sum_{i \in I} g_i)^2}{\sum_{i \in I} h_i +\lambda} \right] - \gamma\]</span></p><ul><li><strong>对数损失</strong></li></ul><p><span class="math display">\[\text{LogLoss} = -\frac{1}{N} \sum_{i=1}^N \left[ y_i \log p_i + (1-y_i)\log(1-p_i) \right]\]</span></p><ul><li><strong>分类错误率</strong></li></ul><p><span class="math display">\[\text{Error} = \frac{1}{N} \sum_{i=1}^N \mathbb{I}(\hat{y}_i \neq y_i)\]</span></p>]]></content>
    
    
    <categories>
      
      <category>数学</category>
      
      <category>算法</category>
      
      <category>机器学习</category>
      
      <category>公式推导</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
