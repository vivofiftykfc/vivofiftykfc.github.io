

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/customer_fluid.png">
  <link rel="icon" href="/img/customer_fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="ZHW">
  <meta name="keywords" content="">
  
    <meta name="description" content="梳理了统计学与数据挖掘的基本概念、方法论及其在数据分析中的应用">
<meta property="og:type" content="article">
<meta property="og:title" content="统计与数据挖掘综述">
<meta property="og:url" content="http://example.com/2025/08/25/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E7%BB%BC%E8%BF%B0%E6%A6%82%E8%A6%81/%E7%BB%9F%E8%AE%A1%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%BB%BC%E8%BF%B0/">
<meta property="og:site_name" content="HWのBLOGS">
<meta property="og:description" content="梳理了统计学与数据挖掘的基本概念、方法论及其在数据分析中的应用">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/blogs/inright.jpg">
<meta property="article:published_time" content="2025-08-25T09:14:11.000Z">
<meta property="article:modified_time" content="2025-09-02T14:59:13.298Z">
<meta property="article:author" content="ZHW">
<meta property="article:tag" content="数学建模">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/blogs/inright.jpg">
  
  
  
  <title>统计与数据挖掘综述 - HWのBLOGS</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":50,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":"ture","follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":"HWzRml8hi2o6Hlgj8gSUyhOw-MdYXbMMI","app_key":"MLwKjXwGIjqYL5XxqjYnBZe5","server_url":null,"path":"window.location.pathname","ignore_local":"ture"},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2025-03-30T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>HWのBIOGS</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/blogs/inright.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="统计与数据挖掘综述"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-08-25 17:14" pubdate>
          2025年8月25日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          13k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          161 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">统计与数据挖掘综述</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="摘要">摘要</h2>
<p>本文系统梳理了统计学与数据挖掘的基本概念、方法论及其在数据分析中的应用。首先从数据理解、准备与建模流程入手，介绍了分类与回归模型的常用评价指标。随后，对集成学习方法（Bagging、Boosting、Stacking、Blending）进行了比较与总结，阐述了其在提升模型性能与鲁棒性方面的作用。在统计分析部分，涵盖了假设检验、列联分析、相关分析、回归分析以及方差分析等核心方法，强调了它们在数据关系探索与显著性验证中的价值。文章进一步综述了预测建模、分类建模、聚类分析、关联与序列模式挖掘，以及Web数据挖掘的典型技术与应用场景。整体而言，本综述将统计学的严谨方法论与数据挖掘的实用算法框架相结合，为理解和解决实际问题提供了系统化的思路，对数学建模及跨学科数据分析研究具有重要的参考价值。</p>
<h2 id="绪论">1. 绪论</h2>
<h3 id="概念">1.1 概念</h3>
<p>数据挖掘从大型数据库中发现数据所表现出的特征，从中归纳得出新知识新方法。</p>
<p>统计学是研究如何测度、收集、整理和分析反映客观现象有关信息的数据，以帮助人们正确认识客观世界数量规律的方法论科学。包括数据采集、数据处理、数据分析的各种统计学方法。</p>
<h3 id="方法论">1.2 方法论</h3>
<p>有一套跨行业数据挖掘标准，具体步骤为：</p>
<ol type="1">
<li><p>商业理解，就是了解国内外研究现状；换句话讲就是明确我们进行数据分析的要求与最终目的是什么，明确数据挖掘能在其中为我带来什么。具体到数学竞赛中，往往目的就很明确了，要做的就是查找相关文献来了解相关的方法，同时进一步明确该方法的复现难度，提升空间。</p></li>
<li><p>数据理解，即了解数据需要进行如何进行预处理；了解数据完整性、正确性，初步掌握数据可能有什么特征，适合用什么样的建模方法</p></li>
<li><p>数据准备，即对数据进行预处理。</p></li>
<li><p>选择合适的建模方法，在确定参数时，可以手工调参，也可采用网格式搜索，即遍历给出的超参数组合来设定模型并训练，或者用随机搜索、贝叶斯搜索法，注意提前熟悉相关内容，预先准备好程序代码。如果不知道哪种建模方法更好，可以训练多个模型，通过一定的结合策略，以集成学习的形式得到一个较好的集成模型。</p></li>
<li><p>评价模型成效；</p></li>
<li><p>输出建模结果。</p></li>
</ol>
<h3 id="模型评价参数">1.3 模型评价参数</h3>
<p>当我们建立好一个模型后，无论是用于分类还是预测，我们都需要一套客观的标准来衡量它的性能。</p>
<h4 id="分类变量预测模型-classification-metrics">分类变量预测模型
(Classification Metrics)</h4>
<p>这类模型预测的是类别，比如“是/否”、“A/B/C类”、“有病/没病”。评价它们时，我们通常会先得到一个叫<strong>混淆矩阵
(Confusion Matrix)</strong>
的东西，它就是一个表格，总结了模型“猜对”和“猜错”的各种情况。</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;"><strong>预测为正例</strong></th>
<th style="text-align: center;"><strong>预测为负例</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>实际为正例</strong></td>
<td style="text-align: center;">真阳性 (TP)</td>
<td style="text-align: center;">假阴性 (FN)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>实际为负例</strong></td>
<td style="text-align: center;">假阳性 (FP)</td>
<td style="text-align: center;">真阴性 (TN)</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>正例 (Positive)</strong>:
通常是我们更关心的那个类别，比如“有病”、“是垃圾邮件”。</li>
<li><strong>TP (True Positive)</strong>:
猜对了，本来是正例，模型也预测是正例。</li>
<li><strong>FN (False Negative)</strong>:
猜错了，本来是正例，模型却预测是负例。（<strong>漏报</strong>）</li>
<li><strong>FP (False Positive)</strong>:
猜错了，本来是负例，模型却预测是正例。（<strong>误报</strong>）</li>
<li><strong>TN (True Negative)</strong>:
猜对了，本来是负例，模型也预测是负例。</li>
</ul>
<p>基于这个矩阵，我们有了下面这些指标：</p>
<ul>
<li><p><strong>准确率 (Accuracy)</strong></p>
<ul>
<li><p><strong>定义：</strong>
所有样本中，被模型正确分类的样本所占的比例。</p></li>
<li><p><strong>公式：</strong>
<code>(TP + TN) / (TP + TN + FP + FN)</code></p></li>
<li><p><strong>局限性：</strong>
在<strong>样本不均衡</strong>的情况下，准确率是个“骗子”。比如，一个癌症检测模型，在1000个样本里只有1个是真病人。如果模型偷懒，把所有人都预测为“没病”，那它的准确率高达99.9%，看起来很棒，但实际上一个病人都没找出来，完全没用。</p></li>
</ul></li>
<li><p><strong>查准率 (Precision)</strong></p>
<ul>
<li><p><strong>定义：</strong>
模型预测为“正例”的样本中，有多少是真正的“正例”。</p></li>
<li><p><strong>公式：</strong> <code>TP / (TP + FP)</code></p></li>
<li><p><strong>应用场景：</strong> 当<strong>误报 (FP)
的代价很高</strong>时，我们希望查准率高。比如垃圾邮件检测，你绝不希望一封重要的工作邮件被误判为垃圾邮件
(FP)，宁可放过一些垃圾邮件。</p></li>
</ul></li>
<li><p><strong>查全率 (Recall) / 召回率</strong></p>
<ul>
<li><p><strong>定义：</strong>
所有真正的“正例”中，有多少被模型成功地找了出来。</p></li>
<li><p><strong>公式：</strong> <code>TP / (TP + FN)</code></p></li>
<li><p><strong>应用场景：</strong> 当<strong>漏报 (FN)
的代价很高</strong>时，我们希望查全率高。比如传染病筛查或癌症诊断，漏掉一个真正的病人
(FN) 后果不堪设想，宁可把一些健康的人叫来复查 (FP)。</p></li>
</ul></li>
<li><p><strong>F1 分数 (F1-Score)</strong></p>
<ul>
<li><p><strong>定义：</strong> 查准率和查全率的调和平均数。</p></li>
<li><p><strong>公式：</strong>
<code>2 * (Precision * Recall) / (Precision + Recall)</code></p></li>
<li><p>查准率和查全率往往是一对矛盾体，一个高了另一个可能就低了。F1分数就是想找一个平衡点，它同时兼顾了这两个指标，只有当两者都比较高时，F1分数才会高。它是一个更综合、更鲁棒的评价指标。</p></li>
</ul></li>
</ul>
<h4 id="连续变量预测模型-regression-metrics">连续变量预测模型
(Regression Metrics)</h4>
<p>这类模型预测的是一个具体的数值，比如房价、气温、股票价格。</p>
<ul>
<li><p><strong>均方误差 (Mean Squared Error, MSE)</strong></p>
<ul>
<li><p><strong>定义：</strong>
就是方差，预测值与真实值之差的平方的平均值。</p></li>
<li><p><strong>公式：</strong> (1/n) * Σ(y_true - y_pred)²</p></li>
<li><p><strong>局限性</strong>：对偏差过大的值较为敏感</p></li>
</ul></li>
<li><p><strong>均方根误差 (Root Mean Squared Error, RMSE)</strong></p>
<ul>
<li><p><strong>定义：</strong> 平方差，就是对MSE开个根号。</p></li>
<li><p><strong>公式：</strong> <code>sqrt(MSE)</code></p></li>
<li><p>开根号的好处是，它的<strong>量纲和原始数据是一样</strong>的。如果你的模型预测的是房价（单位：万元），那么RMSE的单位也是“万元”，这样你就能直观地理解“模型平均预测误差大概在xx万元”这个量级，解释性比MSE好。</p></li>
</ul></li>
<li><p><strong>平均绝对误差 (Mean Absolute Error, MAE)</strong></p>
<ul>
<li><p><strong>定义：</strong>
预测值与真实值之差的绝对值的平均值。</p></li>
<li><p><strong>公式：</strong>
<code>(1/n) * Σ|y_true - y_pred|</code></p></li>
<li><p><strong>用人话讲：</strong>
它同样衡量预测的离谱程度，但因为它用的是绝对值而不是平方，所以它对那些特别离谱的异常值<strong>没有那么敏感</strong>，显得更“温和”，更能反映一般情况下的预测误差。</p></li>
</ul></li>
<li><p><strong>决定系数 (R-squared, R²)</strong></p>
<ul>
<li><p><strong>定义：</strong>
一个衡量模型拟合优度的指标，表示模型的预测结果能解释因变量变化的百分比。</p></li>
<li><p><strong>公式：</strong>
<code>1 - (Σ(y_true - y_pred)² / Σ(y_true - y_mean)²)</code></p></li>
<li><p><strong>用人话讲：</strong>
它的值在0到1之间。可以这样理解：如果我们不用任何模型，直接猜所有样本的值都是平均数（<code>y_mean</code>），这会产生一个总误差。而我们的模型产生的误差是
<code>Σ(y_true - y_pred)²</code>。R²衡量的就是“<strong>我们的模型比瞎猜（猜平均数）好多少</strong>”。</p>
<ul>
<li><strong>R² = 1</strong>：完美模型，预测值和真实值完全一样。</li>
<li><strong>R² = 0</strong>：模型和瞎猜一样烂。</li>
<li><strong>R² &lt; 0</strong>：模型比瞎猜还要烂，简直是帮倒忙。</li>
</ul></li>
<li><p>它提供了一个与量纲无关的、非常直观的“模型好坏”的百分比度量。</p></li>
</ul></li>
</ul>
<h3 id="集成学习方法">1.4 集成学习方法</h3>
<p>集成学习的方法就是多种模型来组合成一个大模型，来提高整体模型店准确性与鲁棒性，具体的话之前的第二次校赛拿几种回归分析组合为一个大分（雾）析就是这样的。</p>
<p>集成学习主要方法归类为下述几种：</p>
<h4 id="装袋bagging">装袋（Bagging）</h4>
<p>这是一种并行集成方法，‌通过构造多个独立的模型，‌然后通过投票、平均或加权的方式构造强学习器。‌</p>
<p><strong>随机森林</strong>是Bagging的一个典型应用，‌它通过构建多个决策树并通过投票或平均来做出最终预测。
‌</p>
<h4 id="提升boosting">提升（Boosting）</h4>
<p>这是一种串行集成方法，‌利用基学习器之间串行的方式进行构造强学习器。‌它通过调整数据点的权重来训练一系列弱学习器，赋予预测错误数据更高权重，使得后继学习器更试图纠正前一个学习器的错误。‌
AdaBoost是一种典型的Boosting方法。</p>
<h4 id="堆叠stacking">堆叠（Stacking）</h4>
<p>结合了Bagging和Boosting两种方法的集成方式。‌将第一层模型的输出作为第二层模型的输入，‌通过模型对原数据的堆叠进行建模，‌提高模型的泛化能力。‌</p>
<h4 id="融合blending">融合（Blending）</h4>
<p>是一种集成学习方法，‌它通过结合多个模型的预测结果来提高预测的准确性和稳定性。‌这种方法主要分为两个阶段：‌第一阶段是训练多个基模型，‌这些基模型可以是同质的（‌使用相同类型的算法）‌或异质的（‌使用不同类型的算法）‌；‌第二阶段是使用第一阶段模型在验证集上的输出结果作为特征，‌训练一个元模型（‌通常是线性回归模型）‌，‌最终利用这个元模型对测试集进行预测。
‌
优点包括：‌易于理解。‌可扩展性高：‌Blending的模型框架具有较高的可扩展性，‌可以根据需要添加或替换基模型。
‌缺点‌则为实现难、计算量大，感觉在国赛中现在我的水平我是不会用的。</p>
<h2 id="数据准备与探索性分析">2. 数据准备与探索性分析</h2>
<h3 id="统计学简介"><strong>2.1 统计学简介</strong></h3>
<p>定义：收集、分析、表述和解释数据的科学。</p>
<p>统计研究过程：收集、整理、分析、解释数据。</p>
<p>基本概念：总体、样本、参数、统计量。</p>
<h3 id="统计数据的分类"><strong>2.2 统计数据的分类</strong></h3>
<p><strong>按计量层次</strong>：定类数据、定序数据、定距型数据。</p>
<p><strong>按收集方法</strong>：观测数据、试验数据。</p>
<p><strong>按时间状况</strong>：截面数据、时间序列数据。</p>
<h3 id="描述统计量"><strong>2.3 描述统计量</strong></h3>
<p><strong>集中趋势</strong>：均值、中位数、众数、总和（及其关系与特点）。</p>
<p><strong>离散趋势</strong>：标准差、方差、最小值、最大值、极差、均值标准误。</p>
<p><strong>形状</strong>：偏度系数（Skewness）、峰度系数（Kurtosis）及其对分布的解释。</p>
<p>标准分数（Standard Score）及其作用。</p>
<h3 id="数据可视化"><strong>2.4 数据可视化</strong></h3>
<p>可视化简介：数据视觉表现形式的科技研究，发展阶段（科学可视化、信息可视化、数据可视化、可视分析）。</p>
<p>DIKW层次模型：数据 -&gt; 信息 -&gt; 知识 -&gt; 智慧的转化过程。</p>
<p><strong>统计图类型</strong>：</p>
<p>条形图：反映分类数据频数分布。</p>
<p>线图：反映变量变化趋势（适用于连续变量）。</p>
<p>箱形图：显示原始数据分布（最大值、最小值、中位数、四分位数），观察分布形状。</p>
<p>散点图：展示两变量间数量关系和趋势。</p>
<p>直方图：反映分组数据的频数分布。</p>
<p>P-P图 / Q-Q图：检验数据是否服从特定理论分布（如正态分布）。</p>
<h3 id="探索性数据分析eda">2.5
<strong>探索性数据分析（EDA）</strong></h3>
<h4 id="介绍">介绍</h4>
<p>它是一种数据统计分析方法，通过可视化图表和统计量表格，在没有太多先验假设的情况下，探索数据的内在结构和规律，提取关键信息
。</p>
<h4 id="分析目的">分析目的</h4>
<ul>
<li><p><strong>数据理解和预处理：</strong>
帮助你弄清数据的含义和结构，发现异常值、缺失值、重复值，以便进行数据清洗和整理
。</p></li>
<li><p><strong>特征描述和关系分析：</strong>
掌握数据的重要信息，比如变量的分布和它们之间的关系 。</p></li>
<li><p><strong>为后续分析做准备：</strong>
帮助你决定是否需要进行数据变换、使用非参数方法或建立线性回归模型，从而将业务问题转化为可行的数据分析问题
。</p></li>
</ul>
<h4 id="分析内容">分析内容</h4>
<ol type="1">
<li><p><strong>数据筛查：</strong>
检查数据是否存在缺失值、异常值、重复值，判断样本是否均衡，以及是否需要抽样、增加新的变量或变量转换
。</p></li>
<li><p><strong>数据特征描述：</strong></p></li>
</ol>
<ul>
<li><p><strong>连续变量：</strong>
使用平均值、中位数、标准差等统计量，以及直方图、箱线图等图表来描述
。</p></li>
<li><p><strong>离散变量（无序型和有序型）：</strong>
使用频数、占比等统计量，以及频数分布表、条形图、饼图来描述 。</p></li>
</ul>
<ol start="3" type="1">
<li><strong>变量关系：</strong></li>
</ol>
<p><strong>连续变量vs.连续变量</strong></p>
<p>这个属于相关分析</p>
<p>图表：散点图、相关系数矩阵、热图</p>
<p>量化指标：Pearson、Spearman、Kendall相关系数。具体可见本站相关文章</p>
<p><strong>离散变量vs.离散变量</strong></p>
<p>图表：两两之间用交叉列联表、复式条形图；多个离散变量中用网格图</p>
<p>有序型离散变量使用相关分析，指标就是那些相关系数</p>
<p>无序型离散变量使用列连分析，量化指标是 <span
class="math inline">\(\varphi\)</span> 相关系数、 <span
class="math inline">\(V\)</span> 相关系数，列联相关系数</p>
<p><strong>离散变量vs.连续变量</strong></p>
<p>图像：直方图、箱线图、小提琴图</p>
<p>量化分析：t检验、方差分析等方法进行量化分析</p>
<p>量化指标：独立样本t检验中t统计量以及相应的p值，单多因素方差分析的统计量</p>
<ol start="4" type="1">
<li>数据正态性检验</li>
</ol>
<p>直方图：看图形与钟形曲线吻合程度</p>
<p>箱线图：看图形是否对称</p>
<p>P-P图：正态分布，数据的累积比例与正态分布累积比例基本保持一致。将数据累积比例为X轴，对应正态分布累积比例为Y轴，作散点图。若各点近似分布在一条直线上,则数据符合指定分布。</p>
<p>Q-Q图：比较数据的分位数与某个理论分布的分位数是否匹配。</p>
<ol start="5" type="1">
<li>检验数据的分布类型</li>
</ol>
<p>夏皮罗－威尔克检验（Shapiro-Wilk test）</p>
<p>科尔莫戈罗夫－斯米尔诺夫检验（Kolmogorov-Smirnov test）</p>
<p>6.数据变换</p>
<p>box-cox变换</p>
<h4 id="用以描述的统计量"><strong>用以描述的统计量</strong></h4>
<ul>
<li><p><strong>集中趋势：</strong></p>
<ul>
<li><p><strong>均值（Mean）：</strong> 最常用，但容易受极端值影响
。</p></li>
<li><p><strong>中位数（Median）：</strong>
数据排序后中间的那个数，不受极端值影响，适用于所有分布 。</p></li>
<li><p><strong>众数（Mode）：</strong>
出现频率最高的数，不受极端值影响，可以有多个 。</p></li>
</ul></li>
<li><p><strong>离散趋势：</strong></p>
<ul>
<li>描述数据分散程度，比如标准差、方差、极差等 。</li>
</ul></li>
</ul>
<h4 id="可视化图表"><strong>可视化图表</strong></h4>
<ul>
<li><p><strong>条形图（Bar chart）：</strong>
用长短表示数据类别频数，适用于离散变量 。</p></li>
<li><p><strong>线图（Line chart）：</strong>
用线条升降表示变量随时间的变化趋势，适用于连续变量 。</p></li>
<li><p><strong>箱形图（Box plot）：</strong>
用箱子和线段展示数据的分布，包括最大值、最小值、中位数和四分位数，可以直观地看出数据的对称性
。</p></li>
</ul>
<h2 id="主要分析方法">3. 主要分析方法</h2>
<h3 id="假设检验-hypothesis-testing"><strong>3.1 假设检验 (Hypothesis
Testing)</strong></h3>
<p>我们有一个怀疑或主张（比如“这个新药有效”），但我们不能直接下结论。我们必须先设定一个原假设H0，通常代表“无效”或“没变化”，并假定它是“无辜的”。然后，我们收集样本数据，看看这些证据是否足够强大，能够“毫无疑义地”（在某个概率水平上）推翻这个“无辜”的假定。</p>
<h4 id="步骤-the-steps-of-the-trial"><strong>步骤 (The Steps of the
Trial)</strong>：</h4>
<ol type="1">
<li><strong>提出假设 (State the Hypotheses)</strong>：</li>
</ol>
<p><strong>原假设 (Null Hypothesis,
H0)</strong>：也叫“零假设”，代表“现状”或“没有效应”。它总是包含等号（=,
≤,
≥）。在法庭上，这就是“被告无罪”。例如：<code>H0: 新药的平均疗效 = 安慰剂的平均疗效</code>。</p>
<p><strong>备择假设 (Alternative Hypothesis, H1 或
Ha)</strong>：这是我们想要证明的、与原假设对立的观点。它总是包含不等号（≠,
&lt;,
&gt;）。在法庭上，这就是“被告有罪”。例如：<code>H1: 新药的平均疗效 ≠ 安慰剂的平均疗效</code>。</p>
<ol start="2" type="1">
<li><strong>规定显著性水平 α (Set the Significance
Level)</strong>：</li>
</ol>
<p>在审判开始前，我们要先设定一个“定罪标准”。这个标准就是显著性水平
α，通常取 0.05。它代表我们愿意承担的“判错案”的风险上限。α = 0.05
意味着，我们允许有5%的概率冤枉一个“好人”（即错误地推翻了一个实际上成立的H0）。</p>
<ol start="3" type="1">
<li><strong>确定并计算检验统计量 (Calculate the Test
Statistic)</strong>：</li>
</ol>
<p>这是将“证据”（样本数据）量化成一个单一数值的过程。这个数值衡量了我们的样本结果与原假设H0之间的差距有多大。不同的问题需要用不同的检验统计量（如Z,
t, χ², F）。</p>
<ol start="4" type="1">
<li><strong>作出统计决策 (Make the Decision)</strong>：</li>
</ol>
<p>这是最后“宣判”的环节。我们有两种方法：
<strong>临界值法</strong>：将计算出的检验统计量与一个“临界值”（根据α查表得出）进行比较。如果统计量落入了“拒绝域”，就拒绝H0。</p>
<p><strong>P值法 (P-value
Approach)</strong>：这是现代统计软件中最常用的方法。计算出一个<strong>p值</strong>，它代表“<strong>如果原假设H0是真的，我们能观测到现有样本结果（或更极端结果）的概率</strong>”。然后将p值与α比较：</p>
<p>如果 <strong>p ≤
α</strong>：说明在H0成立的前提下，发生我们观测到的事件是个小概率事件。我们有理由怀疑H0的真实性，因此<strong>拒绝原假设H0</strong>。</p>
<p>如果 <strong>p &gt;
α</strong>：说明在H0成立的前提下，我们的样本结果很正常，不值得大惊小怪。我们<strong>没有足够证据拒绝原假设H0</strong>。</p>
<p><strong>两类错误 (Two Types of Errors)</strong>：</p>
<p><strong>第一类错误 (Type I Error,
弃真错误)</strong>：原假设H0本来是真的，但我们却错误地拒绝了它。其发生的概率就是我们设定的
<strong>α</strong>。</p>
<p><strong>第二类错误 (Type II Error,
取伪错误)</strong>：原假设H0其实是假的，但我们却没有足够的证据拒绝它，错误地接受了它。其发生的概率用
<strong>β</strong> 表示。</p>
<h4 id="常见检验类型"><strong>常见检验类型</strong></h4>
<h5 id="一个正态总体参数检验">1. 一个正态总体参数检验</h5>
<p><strong>均值检验 (σ 已知) - Z检验</strong>
<strong>问题</strong>：“我知道全国男性的平均身高是175cm，标准差σ是5cm。我随机抽了我们学校100个男生，算出平均身高是177cm。我们学校的男生比全国更高吗？”</p>
<p><strong>检验统计量</strong>：</p>
<p><span class="math display">\[ Z = \frac{\bar{x} - \mu_0}{\sigma /
\sqrt{n}} \]</span></p>
<p>其中 <span class="math inline">\(\bar{x}\)</span> 是样本均值，<span
class="math inline">\(\mu_0\)</span> 是假设的总体均值，<span
class="math inline">\(\sigma\)</span> 是总体标准差，<code>n</code>
是样本量。</p>
<p><strong>均值检验 (σ 未知) - t检验</strong></p>
<p><strong>问题</strong>：这是更常见的情况。“我想知道一批新生产的灯泡的平均寿命是否是800小时。我抽了25个灯泡，测出平均寿命是790小时，样本标准差s是30小时。”</p>
<p><strong>检验统计量</strong>：</p>
<p><span class="math display">\[ t = \frac{\bar{x} - \mu_0}{s /
\sqrt{n}} \]</span></p>
<p>注意这里用的是样本标准差
<code>s</code>。t分布比Z分布更“胖”一点，因为它考虑了用<code>s</code>估计<code>σ</code>带来的额外不确定性。</p>
<p><strong>方差检验 - χ² (卡方) 检验</strong></p>
<p><strong>问题</strong>：“一个零件的生产标准要求其长度的方差不能超过0.01mm²。我抽了30个零件，算出样本方差是0.015mm²。这条生产线的稳定性是否不达标？”</p>
<p><strong>检验统计量</strong>：</p>
<p><span class="math display">\[ \chi^2 = \frac{(n-1)s^2}{\sigma_0^2}
\]</span></p>
<p>其中 <span class="math inline">\(s^2\)</span> 是样本方差，<span
class="math inline">\(\sigma_0^2\)</span> 是假设的总体方差。</p>
<p><strong>比例检验 - Z检验</strong></p>
<p><strong>问题</strong>：“去年我们产品的市场占有率是20%。今年我们搞了市场推广，在1000个新用户里，有230个选择了我们的产品。我们的市场占有率是否显著提升了？”</p>
<p><strong>检验统计量</strong>：</p>
<p><span class="math display">\[ Z = \frac{\hat{p} -
p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}} \]</span></p>
<p>其中 <span class="math inline">\(\hat{p}\)</span>
是样本比例，<code>p₀</code> 是假设的总体比例。</p>
<h5 id="两个正态总体参数检验">2. 两个正态总体参数检验</h5>
<p><strong>双独立样本均值检验 (Independent Samples t-test)</strong></p>
<p><strong>问题</strong>：“A、B两种不同的教学方法，哪种效果更好？我把学生随机分成两组，一组用A方法，一组用B方法，然后比较两组的期末平均分。”</p>
<p><strong>检验统计量 (假设方差相等)</strong>：</p>
<p><span class="math display">\[ t = \frac{(\bar{x}_1 - \bar{x}_2) -
(\mu_1 - \mu_2)_0}{\sqrt{s_p^2 (\frac{1}{n_1} + \frac{1}{n_2})}} \quad ,
\quad s_p^2 = \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}
\]</span></p>
<p>其中 <span class="math inline">\(s_p^2\)</span> 是合并方差。</p>
<p><strong>双独立样本方差检验 - F检验</strong></p>
<p><strong>问题</strong>：“在做上面的t检验之前，我需要先判断两组的方差是否相等。A组分数的方差是100，B组是120。这两个方差有显著差异吗？”</p>
<p><strong>检验统计量</strong>：</p>
<p><span class="math display">\[ F = \frac{s_1^2}{s_2^2} \]</span></p>
<p>习惯上将较大的样本方差放在分子。</p>
<p><strong>配对样本t检验 (Paired Samples t-test)</strong></p>
<p><strong>问题</strong>：“我想知道一种减肥药有没有效果。我找了一批人，记录下他们服药前的体重，再记录下他们服药一个月后的体重，然后比较这两组体重的差异。”</p>
<p><strong>思路</strong>：这不是独立样本，因为数据是“成对”出现的（同一个人前后对比）。我们先计算出每个人的体重<strong>差值d</strong>，然后问题就转化成了<strong>对这些差值d进行单样本t检验</strong>，看差值的平均值
<span class="math inline">\(\bar{d}\)</span> 是否显著不为零。</p>
<p><strong>检验统计量</strong>：</p>
<p><span class="math display">\[ t = \frac{\bar{d} - D_0}{s_d /
\sqrt{n}} \]</span></p>
<p>其中 <code>D₀</code> 通常是0，<code>s_d</code> 是差值 <code>d</code>
的标准差。</p>
<h3 id="列联分析-contingency-analysis"><strong>3.2 列联分析 (Contingency
Analysis)</strong></h3>
<p><strong>目的</strong>：专门用来分析<strong>定性变量（分类变量）</strong>之间是否存在关联。</p>
<ul>
<li><p><strong>分析思路 - 卡方检验 (Chi-squared Test, χ²)</strong>：</p>
<ul>
<li>这个检验的核心思想是“<strong>期望与现实的比较</strong>”。</li>
</ul>
<ol type="1">
<li><p><strong>提出假设
(H0)</strong>：我们先假设这两个变量是<strong>完全独立、互不相干</strong>的。</p></li>
<li><p><strong>计算期望频数 (Expected
Frequency)</strong>：基于“独立”这个假设，我们来算一下，理论上，列联表中每个格子里应该有多少人。</p>
<ul>
<li><strong>公式</strong>：某个格子的期望频数 =
<code>(该格子所在行的总和 × 该格子所在列的总和) / 总人数</code></li>
</ul></li>
<li><p><strong>计算卡方统计量
(χ²)</strong>：现在我们有了“期望”和“现实”（观测频数），就可以计算出卡方值，它衡量了现实与期望之间的总体差距。</p>
<ul>
<li><p><strong>公式</strong>： <span class="math display">\[ \chi^2 =
\sum \frac{(\text{观测频数} - \text{期望频数})^2}{\text{期望频数}}
\]</span></p></li>
<li><p><strong>解读</strong>：如果现实和期望差得很多，算出来的χ²值就会很大，这说明我们的“独立”假设可能站不住脚。</p></li>
</ul></li>
<li><p><strong>作出统计决策</strong>：将计算出的χ²值与临界值比较（或直接看p值）。如果p值小于显著性水平α，我们就拒绝原假设，认为这两个变量之间<strong>存在显著关联</strong>。</p></li>
</ol></li>
<li><p><strong>列联表中的相关测量 (Measures of
Association)</strong>：</p>
<ul>
<li><p>卡方检验只能告诉我们变量之间“有没有”关联，但不能告诉我们这个关联有多“强”。下面的系数就是用来度量关联强度的。</p></li>
<li><p><strong>φ (Phi) 相关系数</strong>：专门用于 <strong>2x2</strong>
列联表。</p>
<ul>
<li><p><strong>公式</strong>： <span class="math inline">\(\phi =
\sqrt{\frac{\chi^2}{n}}\)</span> (n是总样本量)</p></li>
<li><p><strong>解读</strong>：它的值在0到1之间，越接近1，表示关联性越强。</p></li>
</ul></li>
<li><p><strong>V (Cramér's V)
相关系数</strong>：更通用的系数，可用于任意大小的列联表。</p>
<ul>
<li><p><strong>公式</strong>： <span class="math inline">\(V =
\sqrt{\frac{\chi^2}{n \cdot (\min(r, c) - 1)}}\)</span> (r是行数,
c是列数)</p></li>
<li><p><strong>解读</strong>：它的值也在0到1之间，同样是越接近1，关联性越强。这使得它在不同大小的表格之间具有可比性，是实践中最常用的指标之一。</p></li>
</ul></li>
</ul></li>
</ul>
<h3 id="相关分析-correlation-analysis"><strong>3.3 相关分析 (Correlation
Analysis)</strong></h3>
<ul>
<li><p><strong>目的</strong>：判明<strong>定量数据（连续变量）</strong>之间有无关联，以及关联的强度和方向。</p></li>
<li><p><strong>和函数关系之间的区别在于？</strong></p>
<ul>
<li><p><strong>函数关系</strong>：是一种<strong>确定性</strong>的关系，一个X值精确地对应一个Y值。比如，<code>y = 2x + 1</code>。只要x定了，y就定了，没有任何偏差。画出来是完美的一条线。</p></li>
<li><p><strong>相关关系</strong>：是一种<strong>非确定性</strong>的、随机的关系。变量之间存在着大致的趋势，但并不严格。比如，身高和体重，身高越高的人，体重“倾向于”越重，但不是绝对的。画出来是围绕着一条趋势线分布的一团散点。<strong>回归分析研究的就是如何找出这团散点背后的那条“平均趋势线”，而相关分析则衡量这团散点向这条线“靠拢的紧密程度”</strong>。</p></li>
</ul></li>
<li><p><strong>相关关系的测定</strong>：</p>
<ul>
<li><p><strong>图形 - 散点图 (Scatter
Plot)</strong>：这是判断关系最直观的工具。通过观察散点的形态，我们可以看出：</p>
<ul>
<li><p>关系的方向（从左下到右上是正相关，从左上到右下是负相关）。</p></li>
<li><p>关系的形态（是直线还是曲线）。</p></li>
<li><p>关系的强度（点越是紧密地聚集在一条线周围，关系越强）。</p></li>
</ul></li>
<li><p><strong>相关系数 (Correlation
Coefficient)</strong>：将图形化的关系量化成一个具体的数值。</p>
<ul>
<li><p><strong>Pearson简单相关系数 (r)</strong>：</p>
<ul>
<li><p><strong>用途</strong>：最最常用的相关系数，衡量两个<strong>连续变量</strong>之间<strong>线性关系</strong>的强度和方向。</p></li>
<li><p><strong>公式</strong>： <span class="math display">\[ r =
\frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i -
\bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2 \sum_{i=1}^{n}(y_i -
\bar{y})^2}} \]</span></p></li>
<li><p><strong>解读</strong>：</p>
<ul>
<li><p>取值范围在 <strong>-1 到 +1</strong> 之间。</p></li>
<li><p><code>r &gt; 0</code> 为正相关，<code>r &lt; 0</code>
为负相关。</p></li>
<li><p><code>|r|</code> 的绝对值越大，线性关系越强。<code>|r| = 1</code>
表示完全线性相关，所有点都在一条直线上。<code>r = 0</code>
表示没有线性关系。</p></li>
</ul></li>
<li><p><strong>重要前提</strong>：它要求变量服从正态分布，并且对异常值非常敏感。</p></li>
</ul></li>
<li><p><strong>Spearman等级相关系数 (ρ 或 rs)</strong>：</p>
<ul>
<li><p><strong>用途</strong>：当数据不满足正态分布，或者数据是<strong>定序变量（等级数据）</strong>时使用。比如，“产品喜好度排名”和“广告投入排名”之间的关系。</p></li>
<li><p><strong>具体操作</strong>：它不直接用原始数值，而是先把每个变量的数据<strong>从小到大进行排序，用它们的“排名”来代替原始值</strong>。然后，再对这两个排名序列计算皮尔逊相关系数。</p></li>
<li><p><strong>解读</strong>：它衡量的是两个变量单调关系（是不是同增同减）的强度。</p></li>
</ul></li>
<li><p><strong>Kendall's Tau (τ) 相关系数</strong>：</p>
<ul>
<li><p><strong>用途</strong>：也是一种非参数的等级相关系数，同样适用于定序变量。</p></li>
<li><p><strong>具体操作</strong>：它的计算方式更复杂一些。它通过比较数据中所有“<strong>一致对</strong>”（两个变量的排序方向相同）和“<strong>非一致对</strong>”（排序方向相反）的数量来衡量关系。</p></li>
<li><p><strong>解读</strong>：与Spearman相比，Kendall's
Tau对于小样本和有大量相同等级的数据时可能更稳健。</p></li>
</ul></li>
<li><p><strong>相关系数的显著性检验 (t检验)</strong>：</p>
<ul>
<li><p>我们算出来的相关系数r不等于0，但这会不会只是样本的巧合？我们需要检验这个相关性在总体中是否也存在。</p></li>
<li><p><strong>检验统计量</strong>：</p>
<p><span class="math display">\[ t = \frac{r\sqrt{n-2}}{\sqrt{1-r^2}}
\]</span></p></li>
<li><p>将计算出的t值与t分布的临界值比较（或看p值），来判断相关系数是否显著不为零。</p></li>
</ul></li>
</ul></li>
</ul></li>
<li><p><strong>偏相关系数 (Partial Correlation)</strong>：</p>
<ul>
<li><p><strong>目的</strong>：在多元分析中，我们想知道两个变量X1和Y之间的“纯粹”关系，需要<strong>排除掉其他变量（如X2）的干扰</strong>。</p></li>
<li><p><strong>用人话讲</strong>：比如我们发现“冰淇淋销量”(X1)和“溺水人数”(Y)之间有很强的正相关。但这很可能是个伪相关，因为它们都受到了“气温”(X2)这个变量的影响。偏相关分析就是要计算在<strong>控制住“气温”这个变量不变</strong>的前提下，“冰淇淋销量”和“溺水人数”之间还剩下多少相关性。结果很可能是，剩下的相关性几乎为零。</p></li>
</ul></li>
<li><p><strong>3.4 回归分析</strong></p>
<ul>
<li><p><strong>目的</strong>：建立变量间相互依赖的量化关系，进行预测或控制。</p></li>
<li><p><strong>分类</strong>：一元/多元、简单/多重、线性/非线性回归。</p></li>
<li><p><strong>线性回归分析</strong>：</p>
<ul>
<li><p><strong>模型假设</strong>。</p>
<ol type="1">
<li><p><strong>线性
(Linearity)</strong>：自变量和因变量之间必须存在线性关系。</p></li>
<li><p><strong>独立性
(Independence)</strong>：各个观测样本的误差项之间是相互独立的，互不影响。比如你预测今天的股价，那个误差不应该影响你对明天股价误差的判断。</p></li>
<li><p><strong>方差齐性
(Homoscedasticity)</strong>：误差项的方差应该是一个常数，不随自变量的取值而改变。<strong>用人话讲</strong>，就是模型预测的“离谱程度”应该是均匀的，不能在自变量小的时候预测很准，自变量大的时候就预测得非常离谱。</p></li>
<li><p><strong>正态性
(Normality)</strong>：误差项必须服从正态分布。</p></li>
</ol></li>
<li><p><strong>回归系数的最小二乘估计</strong>。</p></li>
<li><p><strong>回归方程的拟合优度</strong>：</p>
<p>决定系数（R²） <span class="math display">\[
  R^2 = 1 - \frac{SS_{Res}}{SS_{Total}}
   \]</span></p>
<p>复相关系数</p>
<p><span class="math display">\[R = \sqrt{R^2}\]</span></p>
<p>修正决定系数</p>
<p><span class="math display">\[R^2_{\text{adj}} = 1 - (1 - R^2) \cdot
\frac{n - 1}{n - p - 1}\]</span></p>
<ul>
<li><p>普通的R²有个毛病——你往模型里加的自变量越多，R²就一定会变大（或不变），哪怕你加的是一个毫无关系的变量（比如用星座来预测房价）。这会误导我们以为模型越复杂越好。</p></li>
<li><p><strong>解读</strong>：修正R²就是给R²打了个“补丁”，它在计算时考虑了自变量的数量。如果你加入的自变量对模型没有显著贡献，修正R²反而会下降。因此，在比较包含不同数量自变量的模型时，<strong>看修正R²比看R²更靠谱</strong>。公式中的 <code>n</code> 是样本量，<code>p</code> 是自变量个数。</p></li>
</ul></li>
<li><p><strong>回归标准误差</strong></p></li>
<li><p><strong>显著性检验</strong></p>
<ul>
<li><p>我们的模型和变量真的有意义吗？还是仅仅是数据巧合？这就需要做显著性检验。</p></li>
<li><p><strong>回归的显著性检验 (F检验)</strong></p></li>
<li><p><strong>目的</strong>：检验整个模型的<strong>总体显著性</strong>。它回答的问题是：“你这个回归方程，作为一个整体，到底有没有用？”</p></li>
<li><p><strong>怎么看</strong>：看F检验的p值。如果p值很小（比如&lt;0.05），我们就有信心拒绝“所有自变量都和因变量没关系”这个原假设，认为这个模型整体上是成立的。</p></li>
<li><p><strong>回归系数的显著性检验 (t检验)</strong></p></li>
<li><p><strong>目的</strong>：检验<strong>每一个自变量</strong>的<strong>个体显著性</strong>。它回答的问题是：“模型里的这个XX变量，它对因变量到底有没有显著的影响？”</p></li>
<li><p><strong>怎么看</strong>：看每个系数对应的t检验的p值。如果某个变量的p值很小（&lt;0.05），说明它是个有用的预测变量。如果p值很大，说明这个变量可能没什么用，可以考虑从模型中剔除。</p></li>
</ul></li>
</ul></li>
<li><p><strong>残差分析</strong>：</p>
<ul>
<li><p><strong>概念</strong>：残差就是“真实值 -
预测值”，是模型没能解释的那部分“意外”。</p></li>
<li><p><strong>目的</strong>：就是通过分析“意外”，看看我们的“理论”是不是出了问题。</p></li>
<li><p><strong>残差图</strong>：这是最重要的诊断工具。我们通常画出“残差
vs.
预测值”的散点图。一个好的残差图，应该像一盘散沙，点在0线上下随机均匀分布，看不出任何模式。</p>
<ul>
<li><p>如果残差图呈现出<strong>喇叭形</strong>或<strong>漏斗形</strong>，说明<strong>方差不齐</strong>。</p></li>
<li><p>如果残差图呈现出明显的<strong>曲线模式</strong>，说明可能存在<strong>非线性关系</strong>。</p></li>
</ul></li>
<li><p><strong>P-P图 /
Q-Q图</strong>：这是专门用来检验<strong>残差正态性</strong>的图形工具。如果点基本都落在对角线上，就说明残差大致服从正态分布。</p></li>
</ul></li>
<li><p><strong>其他问题</strong>：</p></li>
<li><p><strong>自变量筛选方法</strong></p></li>
<li><p>当自变量很多时，我们想选出一组“最佳”的自变量组合。手动筛选太麻烦，于是有了自动筛选的方法。</p>
<ul>
<li><p><strong>前进法 (Forward
Selection)</strong>：像搭积木。从一个空模型开始，每次都把那个能让模型改善最显著的变量加进来，直到没有变量能再提供显著改善为止。</p></li>
<li><p><strong>后退法 (Backward
Elimination)</strong>：像砍树。从包含所有变量的完整模型开始，每次都把那个最没用的变量（p值最大）剔除出去，直到剩下的变量都显著为止。</p></li>
<li><p><strong>逐步回归法 (Stepwise
Regression)</strong>：前进法和后退法的结合体，更加灵活。每引入一个新变量后，都会重新审视一下模型里已有的所有变量，看看有没有哪个因为新成员的加入而变得不那么重要了，如果有就把它踢出去。</p></li>
</ul></li>
<li><p><strong>多重共线性 (Multicollinearity)</strong></p>
<ul>
<li><p><strong>概念</strong>：指在多元回归中，自变量之间存在高度相关关系。</p></li>
<li><p><strong>用人话讲</strong>：就是模型里的几个自变量“说的话都差不多”，信息重叠了。比如，同时用“房屋使用面积”和“房屋建筑面积”来预测房价，这两个变量高度相关，就可能引发多重共线性。</p></li>
<li><p><strong>危害</strong>：它会导致回归系数的估计变得非常不稳定，符号可能与预期相反，t检验也可能不显著，让我们无法准确判断每个自变量的单独贡献。</p></li>
<li><p><strong>诊断</strong>：最常用的指标是<strong>方差扩大因子
(Variance Inflation Factor,
VIF)</strong>。如果某个变量的VIF值很大（通常认为&gt;5或&gt;10），就说明它和其他自变量存在严重的多重共线性问题。</p></li>
</ul></li>
</ul></li>
<li><p><strong>3.5 方差分析 (ANOVA)</strong></p>
<ul>
<li><p><strong>引论</strong>：</p>
<ul>
<li><p>目的：检验多个总体均值是否相等，研究分类型自变量对数值型因变量的影响。</p>
<p>有关术语</p></li>
<li><p>基本思想：比较组间方差（系统误差+随机误差）与组内方差（随机误差），通过F比值判断均值差异是否显著。</p></li>
<li><p>基本假定：正态性、方差齐性、独立性。</p></li>
</ul></li>
<li><p><strong>单因素方差分析</strong>：</p>
<ul>
<li><p>数据结构。</p></li>
<li><p>分析步骤：提出假设、构造检验统计量（SST, SSA,
SSE及其自由度、均方MSA, MSE）、计算F值、统计决策。</p></li>
<li><p>关系强度测量（R²）。</p></li>
<li><p>多重比较：当拒绝原假设后，进一步检验哪些均值之间存在差异（如LSD方法）。</p></li>
</ul></li>
<li><p><strong>双因素方差分析</strong>：</p>
<ul>
<li><p>类型：无交互作用、有交互作用。</p></li>
<li><p>目的：分析两个因素（行因素、列因素）及其交互作用对试验结果的影响。</p></li>
<li><p>数据结构。</p></li>
<li><p>分析步骤：提出假设（行因素、列因素及交互作用）、计算平方和（SST,
SSR, SSC, SSinteract, SSE）、计算均方、计算F值、统计决策。</p></li>
<li><p>关系强度测量。</p></li>
</ul></li>
</ul></li>
</ul>
<h3 id="方差分析-analysis-of-variance-anova"><strong>3.4 方差分析
(Analysis of Variance, ANOVA)</strong></h3>
<ul>
<li><p><strong>引论 (Introduction)</strong></p>
<ul>
<li><p><strong>目的</strong>：方差分析主要用于检验<strong>两个或更多个总体（组）的均值是否相等</strong>。本质上，它研究的是一个或多个<strong>分类型自变量</strong>对一个<strong>数值型因变量</strong>的影响。</p>
<ul>
<li><strong>用人话讲</strong>：当我们想比较的组别超过两个时（比如，比较A、B、C三种教学方法下的学生平均分），做多次t检验会增加犯第一类错误的概率。ANOVA提供了一种“一锅端”的解决方案，一次性判断所有组的均值是否都相等。</li>
</ul></li>
<li><p><strong>有关术语</strong>：</p>
<ul>
<li><p><strong>因素
(Factor)</strong>：就是我们研究的那个分类型自变量，比如“教学方法”。</p></li>
<li><p><strong>水平
(Level)</strong>：因素的不同取值，比如“A方法”、“B方法”、“C方法”。</p></li>
</ul></li>
<li><p><strong>基本思想 (The Core Idea)</strong>：</p>
<ul>
<li><p>ANOVA的精髓在于“<strong>分解总变异</strong>”。它把数据的总波动（总方差）分解为两个部分：</p>
<ol type="1">
<li><p><strong>组间方差 (Between-Group
Variance)</strong>：由不同组别（因素的不同水平）带来的系统性差异。比如，A、B、C三种教学方法本身的效果差异。这部分方差既包含了<strong>系统误差</strong>，也包含了随机误差。</p></li>
<li><p><strong>组内方差 (Within-Group
Variance)</strong>：同一组内部，由于个体差异等随机因素造成的波动。比如，同样用A方法教学，学生的分数也不可能完全一样。这部分方差被认为是纯粹的<strong>随机误差</strong>。</p></li>
</ol></li>
<li><p><strong>F比值</strong>：通过比较这两个方差，我们就能做出判断。
<span class="math display">\[ F =
\frac{\text{组间方差}}{\text{组内方差}} = \frac{MSA}{MSE} \]</span></p>
<ul>
<li><strong>逻辑</strong>：如果原假设“所有组的均值都相等”成立，那么就不存在系统误差，组间方差和组内方差应该差不多大，F比值就会接近1。反之，如果不同组的均值确实有差异，组间方差就会显著大于组内方差，F比值就会很大。</li>
</ul></li>
</ul></li>
<li><p><strong>基本假定
(Assumptions)</strong>：和线性回归一样，ANOVA也有它的“地基”。</p>
<ol type="1">
<li><p><strong>正态性</strong>：各组的样本都分别来自正态分布的总体。</p></li>
<li><p><strong>方差齐性</strong>：各组的总体方差相等。这是ANOVA非常重要的一个前提。</p></li>
<li><p><strong>独立性</strong>：各样本之间是相互独立的。</p></li>
</ol></li>
</ul></li>
</ul>
<h4 id="单因素方差分析-one-way-anova"><strong>单因素方差分析 (One-Way
ANOVA)</strong></h4>
<ul>
<li><p>研究<strong>一个</strong>分类型自变量对一个数值型因变量的影响。</p></li>
<li><p><strong>分析步骤</strong>：</p>
<ol type="1">
<li><strong>提出假设</strong>：
<ul>
<li>H0: <span class="math inline">\(\mu_1 = \mu_2 = \dots =
\mu_k\)</span> (所有组的总体均值都相等)</li>
<li>H1: 至少有两个组的总体均值不相等</li>
</ul></li>
<li><strong>构造检验统计量</strong>：这一步是核心，即分解平方和(Sum of
Squares)。
<ul>
<li><strong>总平方和 (SST, Total Sum of
Squares)</strong>：所有数据点与总平均值的离差平方和，代表了总变异。</li>
<li><strong>组间平方和 (SSA, Sum of Squares Between
Groups)</strong>：也叫处理平方和，代表了由不同组别引起的变异。 <span
class="math display">\[ SSA = \sum_{i=1}^{k} n_i (\bar{x}_i -
\bar{\bar{x}})^2 \]</span> (<span
class="math inline">\(k\)</span>是组数, <span
class="math inline">\(n_i\)</span>是第i组样本量, <span
class="math inline">\(\bar{x}_i\)</span>是第i组均值, <span
class="math inline">\(\bar{\bar{x}}\)</span>是总均值)</li>
<li><strong>组内平方和 (SSE, Sum of Squares Within
Groups)</strong>：也叫误差平方和，代表了随机误差引起的变异。 <span
class="math display">\[ SSE = \sum_{i=1}^{k} \sum_{j=1}^{n_i} (x_{ij} -
\bar{x}_i)^2 \]</span></li>
<li><strong>关系</strong>：<span class="math inline">\(SST = SSA +
SSE\)</span></li>
</ul></li>
<li><strong>计算F值</strong>：
<ul>
<li>为了消除样本量的影响，我们要用平方和除以各自的<strong>自由度
(df)</strong>，得到<strong>均方 (Mean Square)</strong>。
<ul>
<li>组间均方 (MSA): <span class="math inline">\(MSA =
\frac{SSA}{k-1}\)</span></li>
<li>组内均方 (MSE): <span class="math inline">\(MSE =
\frac{SSE}{N-k}\)</span> (N是总样本量)</li>
</ul></li>
<li><strong>F统计量</strong>： <span class="math display">\[ F =
\frac{MSA}{MSE} \]</span></li>
</ul></li>
<li><strong>统计决策</strong>：将计算出的F值与F分布的临界值比较（或看p值）。如果p值
&lt; α，则拒绝H0，说明各组均值之间存在显著差异。</li>
</ol></li>
<li><p><strong>多重比较 (Post-Hoc Multiple Comparisons)</strong>：</p>
<ul>
<li>ANOVA的F检验拒绝了H0，只告诉我们“这些组的均值不全相等”，但没告诉我们<strong>具体是哪些组之间</strong>有差异。是A和B有差异？还是B和C有差异？多重比较就是用来做这个“事后追查”的。</li>
<li><strong>常用方法</strong>：LSD (Least Significant Difference)、Tukey
HSD、Bonferroni等。它们本质上是两两t检验的变体，但对显著性水平进行了修正，以控制整体的第一类错误率。</li>
</ul></li>
</ul>
<hr />
<h4 id="双因素方差分析-two-way-anova"><strong>双因素方差分析 (Two-Way
ANOVA)</strong></h4>
<ul>
<li><p>研究<strong>两个</strong>分类型自变量及其<strong>交互作用</strong>对一个数值型因变量的影响。</p></li>
<li><p><strong>类型</strong>：</p>
<ul>
<li><strong>无交互作用的双因素方差分析</strong>：假定两个因素的影响是相互独立的、可以叠加的。</li>
<li><strong>有交互作用的双因素方差分析</strong>：这是更常见、更现实的情况。它不仅考虑两个因素各自的独立影响（<strong>主效应</strong>），还考虑它们组合在一起时产生的特殊“化学反应”（<strong>交互效应</strong>）。
<ul>
<li><strong>交互效应举例</strong>：假设我们研究“肥料种类”（A/B）和“浇水量”（高/低）对农作物产量的影响。如果A肥在低水量时效果好，B肥在高水量时效果好，这就说明两个因素之间存在交互作用。它们的影响不是简单的1+1=2。</li>
</ul></li>
</ul></li>
<li><p><strong>分析步骤</strong>：</p>
<ol type="1">
<li><strong>提出假设</strong>：现在我们有三套假设要检验。
<ul>
<li>关于<strong>交互作用</strong>的：H0: 两个因素之间没有交互作用。</li>
<li>关于<strong>行因素主效应</strong>的：H0:
行因素的各个水平均值相等。</li>
<li>关于<strong>列因素主效应</strong>的：H0:
列因素的各个水平均值相等。</li>
</ul></li>
<li><strong>计算平方和</strong>：总变异被分解得更细了。
<ul>
<li><span class="math inline">\(SST = SSR + SSC + SS_{interaction} +
SSE\)</span>
<ul>
<li><strong>SST</strong>: 总平方和</li>
<li><strong>SSR (Rows)</strong>: 行因素引起的平方和</li>
<li><strong>SSC (Columns)</strong>: 列因素引起的平方和</li>
<li><strong>SS_interaction</strong>: 交互作用引起的平方和</li>
<li><strong>SSE</strong>: 随机误差平方和</li>
</ul></li>
</ul></li>
<li><strong>计算F值</strong>：我们要分别计算三个F值。
<ul>
<li><span class="math inline">\(F_{interaction} =
\frac{MS_{interaction}}{MSE}\)</span></li>
<li><span class="math inline">\(F_{R} = \frac{MSR}{MSE}\)</span></li>
<li><span class="math inline">\(F_{C} = \frac{MSC}{MSE}\)</span></li>
</ul></li>
<li><strong>统计决策</strong>：
<ul>
<li><strong>首先看交互作用的F检验</strong>。如果交互作用显著，说明两个因素的影响是纠缠在一起的，此时单独分析主效应的意义不大，应重点分析交互效应的模式。</li>
<li>如果交互作用不显著，我们再分别去看两个主效应的F检验，判断每个因素是否对因变量有独立、显著的影响。</li>
</ul></li>
</ol></li>
</ul>
<h2 id="问题建模">4. 问题建模</h2>
<h3 id="预测建模-predictive-modeling">4.1 <strong>预测建模 (Predictive
Modeling)</strong></h3>
<p>利用已有数据，建立数学模型，来预测未来的数值。</p>
<h4 id="回归分析-regression-analysis"><strong>回归分析 (Regression
Analysis)</strong></h4>
<p>（这部分在之前的对话中已经详细展开，此处补充和完善上述提到的其他回归类型。）</p>
<ul>
<li><p><strong>线性回归 (Linear
Regression)</strong>：基础模型，寻找最佳直线（或超平面）来拟合数据。</p></li>
<li><p><strong>岭回归 (Ridge Regression)</strong></p>
<ul>
<li><p><strong>目的</strong>：主要用于解决线性回归中的<strong>多重共线性</strong>问题。当自变量之间高度相关时，普通最小二乘法（OLS）估计的回归系数会非常不稳定，方差很大。</p></li>
<li><p><strong>用人话讲</strong>：岭回归就像是给不稳定的回归系数“上了一道枷锁”。它在最小二乘法的基础上，增加了一个“惩罚项”（L2范数惩罚），这个惩罚项会抑制回归系数变得过大。这种约束使得模型整体上变得更稳定、更可靠，即使牺牲了一点点在训练集上的拟合精度。</p></li>
</ul></li>
<li><p><strong>Lasso回归 (Lasso Regression)</strong></p>
<ul>
<li><p><strong>目的</strong>：它和岭回归很像，也是为了解决多重共线性问题。但它有一个更强大的特性——<strong>特征选择
(Feature Selection)</strong>。</p></li>
<li><p><strong>用人话讲</strong>：Lasso回归用的惩罚项（L1范数惩罚）比岭回归更“狠”。它不仅会抑制系数的大小，还会把那些它认为不重要的自变量的系数<strong>直接压缩到零</strong>。因此，Lasso回归在得到一个稳定模型的同时，还帮我们做了一轮变量筛选，告诉我们哪些变量才是真正重要的。</p></li>
</ul></li>
<li><p><strong>逻辑回归 (Logistic Regression)</strong></p>
<ul>
<li><p><strong>注意</strong>：虽然名字里带“回归”，但它实际上是一个<strong>分类模型</strong>。</p></li>
<li><p><strong>目的</strong>：用于预测一个<strong>二元结果</strong>（是/否，1/0）。比如预测一个用户是否会点击广告，一封邮件是否是垃圾邮件。</p></li>
<li><p><strong>用人话讲</strong>：它通过一个特殊的<strong>Sigmoid函数</strong>，巧妙地将线性回归的连续输出值（可以从负无穷到正无穷）映射到
(0, 1)
区间内。这个输出值就可以被解释为“事件发生的概率”。比如，输出0.8，就表示模型预测有80%的概率是正例。然后我们再设定一个门槛（比如0.5），大于这个门槛就判为1，小于就判为0，从而实现了分类。</p></li>
</ul></li>
</ul>
<h4
id="决策树-回归---cr-tree-classification-and-regression-tree"><strong>决策树
(回归) - C&amp;R Tree (Classification and Regression Tree)</strong></h4>
<ul>
<li><p><strong>目的</strong>：用树状结构来做回归预测。</p></li>
<li><p><strong>用人话讲</strong>：分类决策树的每个叶子节点代表一个类别，而回归树的每个叶子节点则代表一个<strong>具体的数值</strong>。它的构建过程是这样的：树不断地通过对某个特征提出问题（比如“面积是否&lt;80平米？”）来分裂数据，目标是让每次分裂后，新生成的节点（分支）内的因变量（比如房价）的<strong>方差变得最小</strong>。最终，当树停止生长时，一个新样本落入某个叶子节点，它的预测值就是这个叶子节点里所有训练样本的<strong>平均值</strong>。</p></li>
</ul>
<h4 id="xgboost回归-extreme-gradient-boosting"><strong>XGBoost回归
(eXtreme Gradient Boosting)</strong></h4>
<ul>
<li><p><strong>目的</strong>：一种极其强大和高效的集成学习算法。</p></li>
<li><p><strong>用人话讲</strong>：可以把它想象成一个“精英团队在不断学习和弥补错误”。</p>
<ol type="1">
<li><p>第一个学习器（一棵简单的决策树）先对数据进行一个粗略的预测。</p></li>
<li><p>第二个学习器上场，它的任务不是预测原始数据，而是专门学习和预测<strong>第一个学习器没预测对的那部分（残差）</strong>。</p></li>
<li><p>第三个学习器再来学习和预测第二个学习器没预测对的残差……</p></li>
</ol>
<p>这个过程不断迭代，每一棵新树都在弥补前面所有树的不足。XGBoost在这个基础上做了大量的优化，速度极快，效果极好，并且内置了正则化来防止过拟合。</p></li>
</ul>
<h4 id="神经网络-neural-networks"><strong>神经网络 (Neural
Networks)</strong></h4>
<p>通过模拟人脑神经元的连接方式，来学习数据中极其复杂的非线性关系。这个略。</p>
<h4
id="支持向量回归机-support-vector-regression-svr"><strong>支持向量回归机
(Support Vector Regression, SVR)</strong></h4>
<ul>
<li><p><strong>目的</strong>：支持向量机 (SVM) 的回归版本。</p></li>
<li><p><strong>用人话讲</strong>：普通线性回归的目标是找到一条线，让所有点到线的距离平方和最小。而SVR的目标是找到一个“<strong>管道</strong>”或“<strong>街道</strong>”，这个管道的宽度是
<code>2ε</code>。它的目标是让<strong>尽可能多的数据点落在这个管道里</strong>，同时让管道本身尽可能“窄”。对于落在管道外的点，SVR才会计算它们的“损失”。那些决定了管道边界的点，就是“<strong>支持向量</strong>”。这种“对管道内的点不计较”的特性，使得SVR对异常值不那么敏感，模型更稳健。</p></li>
</ul>
<h3 id="分类建模-classification-modeling">4.2 <strong>分类建模
(Classification Modeling)</strong></h3>
<p>利用数学模型，将事物划分到预先定义好的不同类别中。因变量Y是离散的。</p>
<ul>
<li><p><strong>逻辑回归</strong>、<strong>判别分析</strong></p></li>
<li><p><strong>决策树（分类）</strong></p></li>
<li><p><strong>神经网络</strong></p></li>
<li><p><strong>支持向量分类机 (SVC)</strong>：</p>
<p>它的核心思想是在不同类别的样本之间，找到一个“<strong>最宽的街道</strong>”（最大间隔超平面）。街道的边缘由距离最近的几个点（<strong>支持向量</strong>）来支撑。这样划分出来的边界容错性最好。对于线性不可分的数据，它通过“<strong>核技巧</strong>”（Kernel
Trick）将数据映射到更高维的空间，让它们变得线性可分，再寻找那条最宽的街道。</p></li>
<li><p><strong>随机森林 (Random Forest)</strong>：</p>
<p>一种集成学习算法，也是决策树的一种。</p>
<ol type="1">
<li><p>它构建<strong>很多棵不同的决策树</strong>。为了让每棵树都不同，它在训练时采用了两种随机性：一是随机抽取一部分样本（<strong>行抽样</strong>），二是随机抽取一部分特征来参与决策（<strong>列抽样</strong>）。</p></li>
<li><p>当需要做预测时，让森林里的每一棵树都独立地“投票”，最后<strong>少数服从多数</strong>，得票最多的那个类别就是最终的预测结果。</p></li>
</ol>
<p>这种机制极大地提高了模型的准确性和稳定性，并且能有效防止单棵决策树容易出现的过拟合问题。</p></li>
</ul>
<h3 id="关联分析-association-analysis">4.3 <strong>关联分析 (Association
Analysis)</strong></h3>
<p>从一大堆看似无关的事件中，找出“A发生了，B也很可能发生”这种模式。最经典的例子就是“啤酒与尿布”的故事。</p>
<ul>
<li><p><strong>Apriori算法</strong></p>
<ul>
<li><p><strong>核心思想</strong>：“<strong>一个项集如果是频繁的，那么它的所有子集也必须是频繁的。</strong>”
反过来说就是：“如果一个项集不频繁，那么它的所有超集也肯定不频繁。”</p></li>
<li><p><strong>操作</strong>：它像“筛筛子”一样，从包含1个商品的频繁项集开始，一层层地往上找包含2个、3个...商品的频繁项集。在每一层，它都利用上面的核心思想来“剪枝”，提前淘汰掉大量不可能频繁的组合，从而提高效率。</p></li>
</ul></li>
<li><p><strong>FP-growth算法</strong></p>
<ul>
<li><p><strong>核心思想</strong>：Apriori算法需要反复扫描数据库并产生大量候选集，效率不高。FP-growth算法则更高明，它把整个数据库的交易信息压缩到一棵叫<strong>FP树
(Frequent Pattern Tree)</strong> 的特殊树状结构里。</p></li>
<li><p><strong>操作</strong>：它只需要扫描两次数据库：一次是统计商品频率，一次是建树。建好树后，所有的挖掘工作都在这棵紧凑的树上进行，不再需要访问原始数据库，速度大大提升。</p></li>
</ul></li>
<li><p><strong>CARMA算法</strong></p></li>
<li><p><strong>序列模式挖掘算法</strong></p></li>
</ul>
<h3 id="聚类分析-cluster-analysis">4.4 <strong>聚类分析 (Cluster
Analysis)</strong></h3>
<ul>
<li><p><strong>用人话讲</strong>：聚类就是“<strong>人以群分，物以类聚</strong>”。它事先不知道有哪些类别，也没有标准答案。算法需要自己根据数据的“长相”（特征），把相似的样本自动地归为一堆，把不相似的分开。</p></li>
<li><p><strong>系统聚类 (Hierarchical Clustering)</strong></p>
<ul>
<li><strong>操作</strong>：它有两种方式。一种是“凝聚”法，开始时每个点都是一个独立的簇，然后一步步地把最相近的两个簇合并，直到所有点都合并成一个大簇，整个过程就像画一棵“树状图”。另一种是“分裂”法，反过来操作。</li>
</ul></li>
<li><p><strong>K-Means算法</strong></p>
<ul>
<li><strong>操作</strong>：这是最经典的聚类算法之一。
<ol type="1">
<li>你先<strong>指定要聚成几类 (K)</strong>。</li>
<li>算法随机选择K个点作为初始的“簇中心”。</li>
<li>所有其他点根据自己离哪个“簇中心”最近，来决定自己的归属。</li>
<li>然后，重新计算每个簇的“新中心”（该簇所有点的平均位置）。</li>
<li>重复第3、4步，直到簇中心的位置不再变化为止。</li>
</ol></li>
</ul></li>
<li><p><strong>TwoStep算法</strong></p></li>
</ul>
<h3 id="序列分析-sequence-analysis">4.5 <strong>序列分析 (Sequence
Analysis)</strong></h3>
<ul>
<li><p><strong>目的</strong>：与关联分析类似，但它额外考虑了<strong>时间顺序</strong>。它要发现的是形如“顾客先买了A，过了一段时间后，又买了B”这样的<strong>时序模式</strong>。</p></li>
<li><p><strong>用人话讲</strong>：关联分析告诉你顾客的购物篮里同时有什么，而序列分析告诉你顾客的“购物时间线”是怎样的。比如，发现“买了新电脑的顾客，通常会在一个月内购买打印机”，或者“看了电影A的观众，下周很可能会去看它的续集B”。</p></li>
<li><p><strong>应用</strong>：网站点击流分析（分析用户的浏览路径）、客户生命周期价值分析、DNA序列分析等。</p></li>
</ul>
<h3 id="web数据挖掘-web-data-mining">4.6 <strong>Web数据挖掘 (Web Data
Mining)</strong></h3>
<p><strong>目的</strong>：一个综合性的领域，指利用数据挖掘技术从海量的Web数据（包括网页内容、网页链接结构、用户访问日志等）中发现有用的知识和模式。</p>
<p><strong>主要内容</strong>：</p>
<ol type="1">
<li><p><strong>Web内容挖掘 (Web Content
Mining)</strong>：从网页的文本、图片、音视频中提取信息。搜索引擎的网页索引就属于这一类。</p></li>
<li><p><strong>Web结构挖掘 (Web Structure
Mining)</strong>：分析网页之间的链接关系（超链接）。比如，Google著名的PageRank算法就是通过分析网页的链接结构来判断网页的重要性。</p></li>
<li><p><strong>Web使用挖掘 (Web Usage
Mining)</strong>：分析用户的访问日志，发现用户的访问模式和行为习惯。这包括了上面提到的关联分析和序列分析在网站上的具体应用，用于个性化推荐、网站布局优化等。</p></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" class="category-chain-item">数学建模</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E7%BB%BC%E8%BF%B0%E6%A6%82%E8%A6%81/" class="category-chain-item">综述概要</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" class="print-no-link">#数学建模</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>统计与数据挖掘综述</div>
      <div>http://example.com/2025/08/25/数学建模/综述概要/统计与数据挖掘综述/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>ZHW</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年8月25日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="NC - 非商业性使用">
                    <i class="iconfont icon-cc-nc"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - 相同方式共享">
                    <i class="iconfont icon-cc-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/08/25/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E7%BB%BC%E8%BF%B0%E6%A6%82%E8%A6%81/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E4%B8%8E%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%96%B9%E6%B3%95%E7%BB%BC%E8%BF%B0/" title="微分方程与差分方程方法综述">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">微分方程与差分方程方法综述</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/08/21/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E7%BB%BC%E8%BF%B0%E6%A6%82%E8%A6%81/%E6%9C%80%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%BB%BC%E8%BF%B0/" title="最优化方法综述">
                        <span class="hidden-mobile">最优化方法综述</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'vivofiftykfc/blogQA');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
      在看什么呢雑魚~
    </div>
  
  
    <div class="statistics">
  
  

  

</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
